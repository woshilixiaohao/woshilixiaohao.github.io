[{"id":0,"href":"/docs/tech/db/","title":"Db","section":"Tech","content":"关系型数据库 #  mysql\n"},{"id":1,"href":"/docs/tech/go/","title":"Go","section":"Tech","content":"go框架、类库 #  "},{"id":2,"href":"/docs/tech/java/","title":"Java","section":"Tech","content":"java 相关 #  "},{"id":3,"href":"/docs/tech/mq/","title":"Mq","section":"Tech","content":"消息队列 #  kafka、rabbit mq\u0026hellip;\n"},{"id":4,"href":"/docs/tech/nosql/","title":"Nosql","section":"Tech","content":"非关系型数据库 #  常用的就是redis、elasticsearch、mongodb\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;.\n"},{"id":5,"href":"/docs/interview/","title":"Interview","section":"Introduction","content":"面试 #  面试的东西\n"},{"id":6,"href":"/docs/tech/","title":"Tech","section":"Introduction","content":"技术方面 #  记录学习的语言，框架，类库等等。。。。。\n"},{"id":7,"href":"/docs/interview/mysql%E9%9D%A2%E8%AF%95%E9%A2%98/","title":"Mysql面试题","section":"Interview","content":"1��ȫ����ʹ�ó�����mysqldump��set global readonly=true 2��������MDL�����ΰ�ȫ�ظ�С�����ֶ� 3����������С����ͻ����������������\n"},{"id":8,"href":"/docs/interview/redis%E9%9D%A2%E8%AF%95%E9%A2%98/","title":"Redis面试题","section":"Interview","content":"1����ʲô���ݽṹ������ֵ�� 2��rehash���� 3�����ϵײ����ݽṹ 4��IO��·���� 5��AOF�������ݣ�д�ز������֣�AOF��д 6��RDB��save/bgsave��Copy on write��AOF+RDB 7�����ӣ���һ�Σ�ȫ�����ơ������Ӹ��ơ��������� 8���ڱ���3�����񣬼��ء�ѡ����֪ͨ 9���ڱ�ѡ����ɸѡ+���� 10���ڱ���Ⱥ���� pub/sub�����⡢�ӿⶼ��ô��ȡ��Ϣ���ڱ���ô֪���Է����ڱ���ô֪���ӿ� 11�����ĸ��ڱ�ִ�������л� 12��Stringռ���ڴ����Ŀӣ�ѹ���б���ʽ 13���ۺ�ͳ�ơ����򡢶�ֵ���������ֱ���ʲô�������� 14��GEO��������ʲô 15��Redis���������ṹ 16��Redis����ʱ����������2�ַ�ʽ 17��redis��Ϣ��������Щ 18��redis���߳�ģ������������Щ����Щ�����첽��ÿ���������������� 19��cpu��redisӰ�죬���ˡ���CPU��NUMA 20���ж�redis�����ķ��� 21��redis����ѯ������key\n ��ȡRedisʵ���ڵ�ǰ�����µĻ������ܡ� �Ƿ���������ѯ��������ǵĻ�����ʹ������������������ѯ������߰Ѿۺϼ����������ڿ�?�� ���� �Ƿ��Թ���key��������ͬ�Ĺ���ʱ�䣿��������ɾ����key��������ÿ��key�Ĺ���ʱ���ϼ�һ������ ��������ͬʱɾ���� �Ƿ�����bigkey�� ����bigkey��ɾ����������������Redis��4.0�����ϵİ汾������ֱ�������첽�߳� ���Ƽ������߳�������������Redis 4.0��ǰ�İ汾������ʹ��SCAN��������ɾ��������bigkey�ļ��ϲ� ѯ�;ۺϲ���������ʹ��SCAN�����ڿͻ������ɡ� Redis AOF���ü�����ʲô��ҵ����?�Ƿ���ȷ��Ҫ��һ�ɿ��Լ���������������Ҫ�����ܣ�ͬʱҲ���� ���ݶ�ʧ�����Խ�������no-appendfsync-on-rewrite����Ϊyes������AOF��д��fsync��������IO�� Դ������Redis�ӳ����ӡ���Ȼ�� ��������Ҫ����������Ҫ�߿ɿ��ԣ�����ʹ���ٹ�̬����ΪAOF��־ ��д���̡� Redisʵ�����ڴ�ʹ���Ƿ����󣿷���swap�����������ǵĻ��������ӻ����ڴ棬������ʹ��Redis�� Ⱥ����̯����Redis�ļ�ֵ���������ڴ�ѹ����ͬʱ��Ҫ��������Redis�������ڴ���������Ӧ�ù����� ���������� ��Redisʵ�������л����У��Ƿ�������͸����ҳ���ƣ������ǵĻ���ֱ�ӹر��ڴ���ҳ���ƾ����ˡ� �Ƿ�������Redis���Ӽ�Ⱥ�������ǵĻ���������ʵ������������С������2~4GB���������Ӹ���ʱ���� �������ش���RDB�ļ��������� �Ƿ�ʹ���˶���CPU��NUMA�ܹ��Ļ�������Redisʵ����ʹ�ö���CPUʱ�����Ը�Redisʵ���������� �ˣ�ʹ��NUMA�ܹ�ʱ��ע����Redisʵ���������жϴ�������������ͬһ��CPU Socket�ϡ�  22��redis�ڴ�Ч�� ����һ ��INFO����Ƭ����ֵ���ڴ���Ƭ�Զ����� 23�������������ᵼ�½��������뻺�������������������������������������ݷ��͹������������ݴ�������������С 24���������ͣ�ֻ�����桢��д���档���潨��������������̭���ԣ�3�࣬8�֡�LRU��redisʵ�֣���һ�Σ��ڶ��� �����������֡�û�������������֡����ö����ݵģ���ʲô���Ժ� 25������һ���ԣ��ȸ�����ɾredis����ɾredis�ٸ��� 26������ѩ������������͸ 27��������Ⱦ��LRU LRF 28��Redisԭ�Ӳ����� 29���ֲ�ʽ�� 30��ACID 31�����ӹ��ϣ��������ݲ�һ�£���ȡ�������ݣ������������� 32������ԭ�������ò��� 33����ɱ 34����������б�����ݷ�����б\n"},{"id":9,"href":"/docs/tech/db/mysql/","title":"Mysql","section":"Db","content":"Mysql架构 #  MySQL可以分为Server层和存储引擎层两部分。\nServer层包括连接器、查询缓存、分析器、优化器、执行器等，涵盖MySQL的大多数核心服务功能，以及所有的内置函数（如日期、时间、数学和加密函数等），所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图等。\n而存储引擎层负责数据的存储和提取。其架构模式是插件式的，支持InnoDB、MyISAM、Memory等多个存储引擎。现在最常用的存储引擎是InnoDB，它从MySQL 5.5.5版本开始成为了默认存储引擎。\n redo log（重做日志）和 binlog（归档日志） #   redo log是InnoDB引擎特有的；binlog是MySQL的Server层实现的，所有引擎都可以使用。 redo log是物理日志，记录的是“在某个数据页上做了什么修改”；binlog是逻辑日志，记录的是这个语句的原始逻辑，比如“给ID=2这一行的c字段加1 ”。 redo log是循环写的，空间固定会用完；binlog是可以追加写入的。“追加写”是指binlog文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。  redo log用于保证crash-safe能力。innodb_flush_log_at_trx_commit这个参数设置成1的时候，表示每次事务的redo log都直接持久化到磁盘。这个参数我建议你设置成1，这样可以保证MySQL异常重启之后数据不丢失。\nsync_binlog这个参数设置成1的时候，表示每次事务的binlog都持久化到磁盘。这个参数我也建议你设置成1，这样可以保证MySQL异常重启之后binlog不丢失。\n 事务隔离级别 #   读未提交是指，一个事务还没提交时，它做的变更就能被别的事务看到。 读提交是指，一个事务提交之后，它做的变更才会被其他事务看到。 可重复读是指，一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的。 串行化，顾名思义是对于同一行记录，“写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。   多路查找树N #  这个N差不多是1200。这棵树高是4的时候，就可以存1200的3次方个值，这已经17亿了。考虑到树根的数据块总是在内存中的，一个10亿行的表上一个整数字段的索引，查找一个值最多只需要访问3次磁盘。其实，树的第二层也有很大概率在内存中，那么访问磁盘的平均次数就更少了。\n 索引 #  innodb #  根据叶子节点的内容，索引类型分为主键索引和非主键索引。\n主键索引的叶子节点存的是整行数据。在InnoDB里，主键索引也被称为聚簇索引（clustered index）。\n非主键索引的叶子节点内容是主键的值。在InnoDB里，非主键索引也被称为二级索引（secondary index）。\n基于主键索引和普通索引的查询有什么区别？\n 如果语句是select * from T where ID=500，即主键查询方式，则只需要搜索ID这棵B+树； 如果语句是select * from T where k=5，即普通索引查询方式，则需要先搜索k索引树，得到ID的值为500，再到ID索引树搜索一次。这个过程称为回表。  基于非主键索引的查询需要多扫描一棵索引树。\n主键长度越小，普通索引的叶子节点就越小，普通索引占用的空间也就越小。\n覆盖索引 #  由于覆盖索引可以减少树的搜索次数，显著提升查询性能，所以使用覆盖索引是一个常用的性能优化手段。\n如果执行的语句是select ID from T where k between 3 and 5，这时只需要查ID的值，而ID的值已经在k索引树上了，因此可以直接提供查询结果，不需要回表。\n最左原则 #  B+树这种索引结构，可以利用索引的“最左前缀”，来定位记录。\n第一原则是，如果通过调整顺序，可以少维护一个索引，那么这个顺序往往就是需要优先考虑采用的。\n比如上面这个市民表的情况，name字段是比age字段大的 ，那我就建议你创建一个（name,age)的联合索引和一个(age)的单字段索引。\n索引下推 #  mysql\u0026gt; select * from tuser where name like \u0026lsquo;张%\u0026rsquo; and age=10 and ismale=1;\n在MySQL 5.6之前，只能从ID3开始一个个回表。到主键索引上找出数据行，再对比字段值。\n而MySQL 5.6 引入的索引下推优化（index condition pushdown)， 可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数。\n 锁 #  全局锁 #  MySQL提供了一个加全局读锁的方法，命令是 Flush tables with read lock (FTWRL)。当你需要让整个库处于只读状态的时候，可以使用这个命令，之后其他线程的以下语句会被阻塞：数据更新语句（数据的增删改）、数据定义语句（包括建表、修改表结构等）和更新类事务的提交语句。\n**全局锁的典型使用场景是，做全库逻辑备份。**也就是把整库每个表都select出来存成文本。\n官方自带的逻辑备份工具是mysqldump。当mysqldump使用参数–single-transaction的时候，导数据之前就会启动一个事务，来确保拿到一致性视图。(innodb)single-transaction方法只适用于所有的表使用事务引擎的库\n既然要全库只读，为什么不使用set global readonly=true的方式呢？确实readonly方式也可以让全库进入只读状态，但我还是会建议你用FTWRL方式，主要有两个原因：\n 一是，在有些系统中，readonly的值会被用来做其他逻辑，比如用来判断一个库是主库还是备库。因此，修改global变量的方式影响面更大，我不建议你使用。 二是，在异常处理机制上有差异。如果执行FTWRL命令之后由于客户端发生异常断开，那么MySQL会自动释放这个全局锁，整个库回到可以正常更新的状态。而将整个库设置为readonly之后，如果客户端发生异常，则数据库就会一直保持readonly状态，这样会导致整个库长时间处于不可写状态，风险较高。  表锁 #  一种是表锁，一种是元数据锁（meta data lock，MDL)。\n**表锁的语法是 lock tables … read/write。**与FTWRL类似，可以用unlock tables主动释放锁，也可以在客户端断开的时候自动释放。\n**另一类表级的锁是MDL（metadata lock)。**MDL不需要显式使用，在访问一个表的时候会被自动加上。MDL的作用是，保证读写的正确性。\n 读锁之间不互斥，因此你可以有多个线程同时对一张表增删改查。 读写锁之间、写锁之间是互斥的，用来保证变更表结构操作的安全性。因此，如果有两个线程要同时给一个表加字段，其中一个要等另一个执行完才能开始执行。  如何安全地给小表加字段？\n首先我们要解决长事务，事务不提交，就会一直占着MDL锁。在MySQL的information_schema 库的 innodb_trx 表中，你可以查到当前执行中的事务。如果你要做DDL变更的表刚好有长事务在执行，要考虑先暂停DDL，或者kill掉这个长事务。\n在alter table语句里面设定等待时间，如果在这个指定的等待时间里面能够拿到MDL写锁最好，拿不到也不要阻塞后面的业务语句，先放弃。之后开发人员或者DBA再通过重试命令重复这个过程。\n小节 #  全局锁主要用在逻辑备份过程中。对于全部是InnoDB引擎的库，我建议你选择使用–single-transaction参数，对应用会更友好。\n表锁一般是在数据库引擎不支持行锁的时候才会被用到的。如果你发现你的应用程序里有lock tables这样的语句，你需要追查一下，比较可能的情况是：\n 要么是你的系统现在还在用MyISAM这类不支持事务的引擎，那要安排升级换引擎； 要么是你的引擎升级了，但是代码还没升级。我见过这样的情况，最后业务开发就是把lock tables 和 unlock tables 改成 begin 和 commit，问题就解决了。  MDL会直到事务提交才释放，在做表结构变更的时候，你一定要小心不要导致锁住线上查询和更新。\n行锁 #  在InnoDB事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。这个就是两阶段锁协议。\n事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放。\n 从顾客A账户余额中扣除电影票价； 给影院B的账户余额增加这张电影票价； 记录一条交易日志。  根据两阶段锁协议，不论你怎样安排语句顺序，所有的操作需要的行锁都是在事务提交的时候才释放的。所以，如果你把语句2安排在最后，比如按照3、1、2这样的顺序，那么影院账户余额这一行的锁时间就最少。这就最大程度地减少了事务之间的锁等待，提升了并发度。\n死锁和死锁检测 #   一种策略是，直接进入等待，直到超时。这个超时时间可以通过参数innodb_lock_wait_timeout来设置。 另一种策略是，发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数innodb_deadlock_detect设置为on，表示开启这个逻辑。  就是如果你能确保这个业务一定不会出现死锁，可以临时把死锁检测关掉。\n另一个思路是控制并发度。\n考虑通过将一行改成逻辑上的多行来减少锁冲突。还是以影院账户为例，可以考虑放在多条记录上，比如10个记录，影院的账户总额等于这10个记录的值的总和。这样每次要给影院账户加金额的时候，随机选其中一条记录来加。这样每次冲突概率变成原来的1/10，可以减少锁等待个数，也就减少了死锁检测的CPU消耗。\n 事务隔离 #  mysql一共2中视图\n 一个是view。它是一个用查询语句定义的虚拟表，在调用的时候执行查询语句并生成结果。创建视图的语法是create view … ，而它的查询方法与表一样。 另一个是InnoDB在实现MVCC时用到的一致性读视图，即consistent read view，用于支持RC（Read Committed，读提交）和RR（Repeatable Read，可重复读）隔离级别的实现。  当前事务的启动瞬间来说，一个数据版本的row trx_id，有以下几种可能：\n 如果落在绿色部分，表示这个版本是已提交的事务或者是当前事务自己生成的，这个数据是可见的； 如果落在红色部分，表示这个版本是由将来启动的事务生成的，是肯定不可见的； 如果落在黄色部分，那就包括两种情况 a. 若 row trx_id在数组中，表示这个版本是由还没提交的事务生成的，不可见； b. 若 row trx_id不在数组中，表示这个版本是已经提交了的事务生成的，可见。  InnoDB利用了“所有数据都有多个版本”的这个特性，实现了“秒级创建快照”的能力。\n一个数据版本，对于一个事务视图来说，除了自己的更新总是可见以外，有三种情况：\n 版本未提交，不可见； 版本已提交，但是是在视图创建后提交的，不可见； 版本已提交，而且是在视图创建前提交的，可见。  更新数据都是先读后写的，而这个读，只能读当前的值，称为“当前读”（current read）。\n可重复读的核心就是一致性读（consistent read）；而事务更新数据的时候，只能用当前读。如果当前的记录的行锁被其他事务占用的话，就需要进入锁等待。\n而读提交的逻辑和可重复读的逻辑类似，它们最主要的区别是：\n 在可重复读隔离级别下，只需要在事务开始的时候创建一致性视图，之后事务里的其他查询都共用这个一致性视图； 在读提交隔离级别下，每一个语句执行前都会重新算出一个新的视图。   普通索引和唯一索引 #  查询能力上是没差别的，主要考虑的是对更新性能的影响。所以，我建议你尽量选择普通索引。\n第一种情况是，这个记录要更新的目标页在内存中。这时，InnoDB的处理流程如下：\n 对于唯一索引来说，找到3和5之间的位置，判断到没有冲突，插入这个值，语句执行结束； 对于普通索引来说，找到3和5之间的位置，插入这个值，语句执行结束。  这样看来，普通索引和唯一索引对更新语句性能影响的差别，只是一个判断，只会耗费微小的CPU时间。\n但，这不是我们关注的重点。\n第二种情况是，这个记录要更新的目标页不在内存中。这时，InnoDB的处理流程如下：\n 对于唯一索引来说，需要将数据页读入内存，判断到没有冲突，插入这个值，语句执行结束； 对于普通索引来说，则是将更新记录在change buffer，语句执行就结束了。  将数据从磁盘读入内存涉及随机IO的访问，是数据库里面成本最高的操作之一。change buffer因为减少了随机磁盘访问，所以对更新性能的提升是会很明显的。\nchange buffer只限于用在普通索引的场景下，而不适用于唯一索引。\n写多读少的业务来说，页面在写完以后马上被访问到的概率比较小，此时change buffer的使用效果最好。\n反过来，假设一个业务的更新模式是写入之后马上会做查询，那么即使满足了条件，将更新先记录在change buffer，但之后由于马上要访问这个数据页，会立即触发merge过程。这样随机访问IO的次数不会减少，反而增加了change buffer的维护代价。所以，对于这种业务模式来说，change buffer反而起到了副作用。\n最佳实践 #  如果所有的更新后面，都马上伴随着对这个记录的查询，那么你应该关闭change buffer。而在其他情况下，change buffer都能提升更新性能。\n在实际使用中，你会发现，普通索引和change buffer的配合使用，对于数据量大的表的更新优化还是很明显的。\nredo log 主要节省的是随机写磁盘的IO消耗（转成顺序写），而change buffer主要节省的则是随机读磁盘的IO消耗。\n 索引选错 #  采用force index强行选择一个索引\n第二种方法就是，我们可以考虑修改语句，引导MySQL使用我们期望的索引\n在有些场景下，我们可以新建一个更合适的索引，来提供给优化器做选择，或删掉误用的索引。\n对于由于索引统计信息不准确导致的问题，你可以用analyze table来解决。\n而对于其他优化器误判的情况，你可以在应用端用force index来强行指定索引，也可以通过修改语句来引导优化器，还可以通过增加或者删除索引来绕过这个问题。\n 怎么给字符串字段加索引？ #  使用前缀索引，定义好长度，就可以做到既节省空间，又不用额外增加太多的查询成本。\n实际上，我们在建立索引时关注的是区分度，区分度越高越好。因为区分度越高，意味着重复的键值越少。因此，我们可以通过统计索引上有多少个不同的值来判断要使用多长的前缀。\n前缀索引对覆盖索引的影响 #  使用前缀索引就用不上覆盖索引对查询性能的优化了，这也是你在选择是否使用前缀索引时需要考虑的一个因素。\n使用倒序存储和使用hash字段这两种方法的异同点。\n首先，它们的相同点是，都不支持范围查询。倒序存储的字段上创建的索引是按照倒序字符串的方式排序的，已经没有办法利用索引方式查出身份证号码在[ID_X, ID_Y]的所有市民了。同样地，hash字段的方式也只能支持等值查询。\n它们的区别，主要体现在以下三个方面：\n 从占用的额外空间来看，倒序存储方式在主键索引上，不会消耗额外的存储空间，而hash字段方法需要增加一个字段。当然，倒序存储方式使用4个字节的前缀长度应该是不够的，如果再长一点，这个消耗跟额外这个hash字段也差不多抵消了。 在CPU消耗方面，倒序方式每次写和读的时候，都需要额外调用一次reverse函数，而hash字段的方式需要额外调用一次crc32()函数。如果只从这两个函数的计算复杂度来看的话，reverse函数额外消耗的CPU资源会更小些。 从查询效率上看，使用hash字段方式的查询性能相对更稳定一些。因为crc32算出来的值虽然有冲突的概率，但是概率非常小，可以认为每次查询的平均扫描行数接近1。而倒序存储方式毕竟还是用的前缀索引的方式，也就是说还是会增加扫描行数。  小节 #  符串字段创建索引的场景。我们来回顾一下，你可以使用的方式有：\n 直接创建完整索引，这样可能比较占用空间； 创建前缀索引，节省空间，但会增加查询扫描次数，并且不能使用覆盖索引； 倒序存储，再创建前缀索引，用于绕过字符串本身前缀的区分度不够的问题； 创建hash字段索引，查询性能稳定，有额外的存储和计算消耗，跟第三种方式一样，都不支持范围扫描。   mysql有时抖一下 #  利用WAL技术，数据库将随机写转换成了顺序写，大大提升了数据库的性能。\n但是，由此也带来了内存脏页的问题。脏页会被后台线程自动flush，也会由于数据页淘汰而触发flush，而刷脏页的过程由于会占用资源，可能会让你的更新和查询语句的响应时间长一些。在文章里，我也给你介绍了控制刷脏页的方法和对应的监控方式。\n第一种是“redo log写满了，要flush脏页”，这种情况是InnoDB要尽量避免的。因为出现这种情况的时候，整个系统就不能再接受更新了，所有的更新都必须堵住。如果你从监控上看，这时候更新数会跌为0。\n第二种是“内存不够用了，要先将脏页写到磁盘”，这种情况其实是常态。InnoDB用缓冲池（buffer pool）管理内存，缓冲池中的内存页有三种状态：\n 第一种是，还没有使用的； 第二种是，使用了并且是干净页； 第三种是，使用了并且是脏页。  刷脏页虽然是常态，但是出现以下这两种情况，都是会明显影响性能的：\n 一个查询要淘汰的脏页个数太多，会导致查询的响应时间明显变长； 日志写满，更新全部堵住，写性能跌为0，这种情况对敏感业务来说，是不能接受的。  innodb刷脏页策略 #  innodb_io_capacity这个参数了，它会告诉InnoDB你的磁盘能力。这个值我建议你设置成磁盘的IOPS\n要合理地设置innodb_io_capacity的值，并且平时要多关注脏页比例，不要让它经常接近75%。\n在InnoDB中，innodb_flush_neighbors 参数就是用来控制这个行为的，值为1的时候会有上述的“连坐”机制，值为0时表示不找邻居，自己刷自己的。\n找“邻居”这个优化在机械硬盘时代是很有意义的，可以减少很多随机IO。机械硬盘的随机IOPS一般只有几百，相同的逻辑操作减少随机IO就意味着系统性能的大幅度提升。\n而如果使用的是SSD这类IOPS比较高的设备的话，我就建议你把innodb_flush_neighbors的值设置成0。因为这时候IOPS往往不是瓶颈，而“只刷自己”，就能更快地执行完必要的刷脏页操作，减少SQL语句响应时间。\n在MySQL 8.0中，innodb_flush_neighbors参数的默认值已经是0了。\n 数据删除空间没小 #  参数innodb_file_per_table #  表数据既可以存在共享表空间里，也可以是单独的文件。这个行为是由参数innodb_file_per_table控制的：\n 这个参数设置为OFF表示的是，表的数据放在系统共享表空间，也就是跟数据字典放在一起； 这个参数设置为ON表示的是，每个InnoDB表数据存储在一个以 .ibd为后缀的文件中。  数据删除流程 #  delete命令其实只是把记录的位置，或者数据页标记为了“可复用”，但磁盘文件的大小是不会变的。也就是说，通过delete命令是不能回收表空间的。这些可以复用，而没有被使用的空间，看起来就像是“空洞”。\n**不止是删除数据会造成空洞，插入数据也会。**因为数据插入造成页分裂这种情况。\n重建表可以空间收缩\nMySQL 5.6版本开始引入的Online DDL，对这个操作流程做了优化。\n我给你简单描述一下引入了Online DDL之后，重建表的流程：\n 建立一个临时文件，扫描表A主键的所有数据页； 用数据页中表A的记录生成B+树，存储到临时文件中； 生成临时文件的过程中，将所有对A的操作记录在一个日志文件（row log）中，对应的是图中state2的状态； 临时文件生成后，将日志文件中的操作应用到临时文件，得到一个逻辑数据上与表A相同的数据文件，对应的就是图中state3的状态； 用临时文件替换表A的数据文件  optimize table、analyze table和alter table这三种方式重建表的区别。这里，我顺便再简单和你解释一下。\n 从MySQL 5.6版本开始，alter table t engine = InnoDB（也就是recreate）默认的就是上面图4的流程了； analyze table t 其实不是重建表，只是对表的索引信息做重新统计，没有修改数据，这个过程中加了MDL读锁； optimize table t 等于recreate+analyze。   count(*) #  你首先要明确的是，在不同的MySQL引擎中，count(*)有不同的实现方式。\n MyISAM引擎把一个表的总行数存在了磁盘上，因此执行count(*)的时候会直接返回这个数，效率很高； 而InnoDB引擎就麻烦了，它执行count(*)的时候，需要把数据一行一行地从引擎里面读出来，然后累积计数。  这篇文章里讨论的是没有过滤条件的count(*)，如果加了where 条件的话，MyISAM表也是不能返回得这么快的。\nInnoDB是索引组织表，主键索引树的叶子节点是数据，而普通索引树的叶子节点是主键值。所以，普通索引树比主键索引树小很多。对于count(*)这样的操作，遍历哪个索引树得到的结果逻辑上都是一样的。因此，MySQL优化器会找到最小的那棵树来遍历。在保证逻辑正确的前提下，尽量减少扫描的数据量，是数据库系统设计的通用法则之一。\n MyISAM表虽然count(*)很快，但是不支持事务； show table status命令虽然返回很快，但是不准确； InnoDB表直接count(*)会遍历全表，虽然结果准确，但会导致性能问题。  count(*)、count(主键id)和count(1) 都表示返回满足条件的结果集的总行数；而count(字段），则表示返回满足条件的数据行里面，参数“字段”不为NULL的总个数。\n对于count(主键id)来说，InnoDB引擎会遍历整张表，把每一行的id值都取出来，返回给server层。server层拿到id后，判断是不可能为空的，就按行累加。\n对于count(1)来说，InnoDB引擎遍历整张表，但不取值。server层对于返回的每一行，放一个数字“1”进去，判断是不可能为空的，按行累加。\n单看这两个用法的差别的话，你能对比出来，count(1)执行得要比count(主键id)快。因为从引擎返回id会涉及到解析数据行，以及拷贝字段值的操作。\n对于count(字段)来说：\n 如果这个“字段”是定义为not null的话，一行行地从记录里面读出这个字段，判断不能为null，按行累加； 如果这个“字段”定义允许为null，那么执行的时候，判断到有可能是null，还要把值取出来再判断一下，不是null才累加。   order by #  全字段排序 #  Extra这个字段中的“Using filesort”表示的就是需要排序，MySQL会给每个线程分配一块内存用于排序，称为sort_buffer。\n通常情况下，这个语句执行流程如下所示 ：\n 初始化sort_buffer，确定放入name、city、age这三个字段； 从索引city找到第一个满足city=\u0026lsquo;杭州’条件的主键id，也就是图中的ID_X； 到主键id索引取出整行，取name、city、age三个字段的值，存入sort_buffer中； 从索引city取下一个记录的主键id； 重复步骤3、4直到city的值不满足查询条件为止，对应的主键id也就是图中的ID_Y； 对sort_buffer中的数据按照字段name做快速排序； 按照排序结果取前1000行返回给客户端。  number_of_tmp_files表示的是，排序过程中使用的临时文件数。你一定奇怪，为什么需要12个文件？内存放不下时，就需要使用外部排序，外部排序一般使用归并排序算法。可以这么简单理解，MySQL将需要排序的数据分成12份，每一份单独排序后存在这些临时文件中。然后把这12个有序文件再合并成一个有序的大文件。\n如果sort_buffer_size超过了需要排序的数据量的大小，number_of_tmp_files就是0，表示排序可以直接在内存中完成。\nrowid #  max_length_for_sort_data，是MySQL中专门控制用于排序的行数据的长度的一个参数。它的意思是，如果单行的长度超过这个值，MySQL就认为单行太大，要换一个算法。\ncity、name、age 这三个字段的定义总长度是36，我把max_length_for_sort_data设置为16，我们再来看看计算过程有什么改变。\n新的算法放入sort_buffer的字段，只有要排序的列（即name字段）和主键id。\n但这时，排序的结果就因为少了city和age字段的值，不能直接返回了，整个执行流程就变成如下所示的样子：\n 初始化sort_buffer，确定放入两个字段，即name和id； 从索引city找到第一个满足city=\u0026lsquo;杭州’条件的主键id，也就是图中的ID_X； 到主键id索引取出整行，取name、id这两个字段，存入sort_buffer中； 从索引city取下一个记录的主键id； 重复步骤3、4直到不满足city=\u0026lsquo;杭州’条件为止，也就是图中的ID_Y； 对sort_buffer中的数据按照字段name进行排序； 遍历排序结果，取前1000行，并按照id的值回到原表中取出city、name和age三个字段返回给客户端。  从OPTIMIZER_TRACE的结果中，你还能看到另外两个信息也变了。\n sort_mode变成了\u0026lt;sort_key, rowid\u0026gt;，表示参与排序的只有name和id这两个字段。 number_of_tmp_files变成10了，是因为这时候参与排序的行数虽然仍然是4000行，但是每一行都变小了，因此需要排序的总数据量就变小了，需要的临时文件也相应地变少了。  覆盖索引 #  Extra字段里面多了“Using index”，表示的就是使用了覆盖索引，性能上会快很多。\n当然，这里并不是说要为了每个查询能用上覆盖索引，就要把语句中涉及的字段都建上联合索引，毕竟索引还是有维护代价的。这是一个需要权衡的决定。\n 随机消息 #  mysql\u0026gt; select word from words order by rand() limit 3;\norder by rand()使用了内存临时表，内存临时表排序的时候使用了rowid排序方法。\n对于内存表，回表过程只是简单地根据数据行的位置，直接访问内存得到数据，根本不会导致多访问磁盘\n如果你创建的表没有主键，或者把一个表的主键删掉了，那么InnoDB会自己生成一个长度为6字节的rowid来作为主键。\n这也就是排序模式里面，rowid名字的来历。实际上它表示的是：每个引擎用来唯一标识数据行的信息。\n 对于有主键的InnoDB表来说，这个rowid就是主键ID； 对于没有主键的InnoDB表来说，这个rowid就是由系统生成的； MEMORY引擎不是索引组织表。在这个例子里面，你可以认为它就是一个数组。因此，这个rowid其实就是数组的下标。  得到严格随机的结果，你可以用下面这个流程:\n 取得整个表的行数，并记为C。 取得 Y = floor(C * rand())。 floor函数在这里的作用，就是取整数部分。 再用limit Y,1 取得一行。  要随机取3个word值呢？你可以这么做：\n 取得整个表的行数，记为C； 根据相同的随机方法得到Y1、Y2、Y3； 再执行三个limit Y, 1语句得到三行数据。  如果你直接使用order by rand()，这个语句需要Using temporary 和 Using filesort，查询的执行代价往往是比较大的。所以，在设计的时候你要量避开这种写法。\n mysql\u0026gt; select count(*) from tradelog where month(t_modified)=7;\n对索引字段做函数操作，可能会破坏索引值的有序性，因此优化器就决定放弃走树搜索功能。\n 查询时间长 #  第一类：查询长时间不返回 #  这个状态表示的是，现在有一个线程正在表t上请求或者持有MDL写锁，把select语句堵住了。\n等行锁\n第二类：查询慢 #  可能会出现的被锁住和执行慢的例子。这其中涉及到了表锁、行锁和一致性读的概念。\n 总结的加锁规则里面，包含了两个“原则”、两个“优化”和一个“bug”。\n 原则1：加锁的基本单位是next-key lock。希望你还记得，next-key lock是前开后闭区间。 原则2：查找过程中访问到的对象才会加锁。 优化1：索引上的等值查询，给唯一索引加锁的时候，next-key lock退化为行锁。 优化2：索引上的等值查询，向右遍历时且最后一个值不满足等值条件的时候，next-key lock退化为间隙锁。 一个bug：唯一索引上的范围查询会访问到不满足条件的第一个值为止。   MySQL有哪些“饮鸩止渴”提高性能的方法？ #  短连接 #  先处理掉那些占着连接但是不工作的线程。\n减少连接过程的消耗。 关闭连接校验\n慢查询性能问题 #  在MySQL中，会引发性能问题的慢查询，大体有以下三种可能：\n 索引没有设计好； SQL语句没写好； MySQL选错了索引。   如果你的MySQL现在出现了性能瓶颈，而且瓶颈在IO上，可以通过哪些方法来提升性能呢？\n针对这个问题，可以考虑以下三种方法：\n 设置 binlog_group_commit_sync_delay 和 binlog_group_commit_sync_no_delay_count参数，减少binlog的写盘次数。这个方法是基于“额外的故意等待”来实现的，因此可能会增加语句的响应时间，但没有丢失数据的风险。 将sync_binlog 设置为大于1的值（比较常见是100~1000）。这样做的风险是，主机掉电时会丢binlog日志。 将innodb_flush_log_at_trx_commit设置为2。这样做的风险是，主机掉电的时候会丢数据。   双主\nbinlog循环依赖可以通过不同的serverid解决\n 规定两个库的server id必须不同，如果相同，则它们之间不能设定为主备关系； 一个备库接到binlog并在重放的过程中，生成与原binlog的server id相同的新的binlog； 每个库在收到从自己的主库发过来的日志后，先判断server id，如果跟自己的相同，表示这个日志是自己生成的，就直接丢弃这个日志。  为什么会有mixed格式的binlog？ #  基于上面的信息，我们来讨论一个问题：**为什么会有mixed这种binlog格式的存在场景？**推论过程是这样的：\n 因为有些statement格式的binlog可能会导致主备不一致，所以要使用row格式。 但row格式的缺点是，很占空间。比如你用一个delete语句删掉10万行数据，用statement的话就是一个SQL语句被记录到binlog中，占用几十个字节的空间。但如果用row格式的binlog，就要把这10万条记录都写到binlog中。这样做，不仅会占用更大的空间，同时写binlog也要耗费IO资源，影响执行速度。 所以，MySQL就取了个折中方案，也就是有了mixed格式的binlog。mixed格式的意思是，MySQL自己会判断这条SQL语句是否可能引起主备不一致，如果有可能，就用row格式，否则就用statement格式。  也就是说，mixed格式可以利用statment格式的优点，同时又避免了数据不一致的风险。\n可靠性优先策略 #  在图1的双M结构下，从状态1到状态2切换的详细过程是这样的：\n 判断备库B现在的seconds_behind_master，如果小于某个值（比如5秒）继续下一步，否则持续重试这一步； 把主库A改成只读状态，即把readonly设置为true； 判断备库B的seconds_behind_master的值，直到这个值变成0为止； 把备库B改成可读写状态，也就是把readonly 设置为false； 把业务请求切到备库B。   每种自增id有各自的应用场景，在达到上限后的表现也不同：\n 表的自增id达到上限后，再申请时它的值就不会改变，进而导致继续插入数据时报主键冲突的错误。 row_id达到上限后，则会归0再重新递增，如果出现相同的row_id，后写的数据会覆盖之前的数据。 Xid只需要不在同一个binlog文件中出现重复值即可。虽然理论上会出现重复值，但是概率极小，可以忽略不计。 InnoDB的max_trx_id 递增值每次MySQL重启都会被保存起来，所以我们文章中提到的脏读的例子就是一个必现的bug，好在留给我们的时间还很充裕。 thread_id是我们使用中最常见的，而且也是处理得最好的一个自增id逻辑了。   主从不一致 #  semi-sync #  要解决这个问题，就要引入半同步复制，也就是semi-sync replication。\nsemi-sync做了这样的设计：\n 事务提交的时候，主库把binlog发给从库； 从库收到binlog以后，发回给主库一个ack，表示收到了； 主库收到这个ack以后，才能给客户端返回“事务完成”的确认。  semi-sync配合判断主备无延迟的方案，存在两个问题：\n 一主多从的时候，在某些从库执行查询请求会存在过期读的现象； 在持续延迟的情况下，可能出现过度等待的问题。  等主库位点方案 #  要理解等主库位点方案，我需要先和你介绍一条命令：\nselect master_pos_wait(file, pos[, timeout]);\r这条命令的逻辑如下：\n 它是在从库执行的； 参数file和pos指的是主库上的文件名和位置； timeout可选，设置为正整数N表示这个函数最多等待N秒。  要保证能够查到正确的数据，我们可以使用这个逻辑：\n trx1事务更新完成后，马上执行show master status得到当前主库执行到的File和Position； 选定一个从库执行查询语句； 在从库上执行select master_pos_wait(File, Position, 1)； 如果返回值是\u0026gt;=0的正整数，则在这个从库执行查询语句； 否则，到主库执行查询语句。  GTID方案 #  如果你的数据库开启了GTID模式，对应的也有等待GTID的方案。\nMySQL中同样提供了一个类似的命令：\n select wait_for_executed_gtid_set(gtid_set, 1);\r这条命令的逻辑是：\n 等待，直到这个库执行的事务中包含传入的gtid_set，返回0； 超时返回1。  在前面等位点的方案中，我们执行完事务后，还要主动去主库执行show master status。而MySQL 5.7.6版本开始，允许在执行完更新类事务后，把这个事务的GTID返回给客户端，这样等GTID的方案就可以减少一次查询。\n这时，等GTID的执行流程就变成了：\n trx1事务更新完成后，从返回包直接获取这个事务的GTID，记为gtid1； 选定一个从库执行查询语句； 在从库上执行 select wait_for_executed_gtid_set(gtid1, 1)； 如果返回值是0，则在这个从库执行查询语句； 否则，到主库执行查询语句。   select 1这样的方法是不是已经被淘汰了呢，但实际上使用非常广泛的MHA（Master High Availability），默认使用的就是这个方法。\nMHA中的另一个可选方法是只做连接，就是 “如果连接成功就认为主库没问题”。不过据我所知，选择这个方法的很少。\n其实，每个改进的方案，都会增加额外损耗，并不能用“对错”做直接判断，需要你根据业务实际情况去做权衡。\n我个人比较倾向的方案，是优先考虑update系统表，然后再配合增加检测performance_schema的信息。\n 什么时候会用到临时表 #  union\ngroupby：用临时表排序\ngroupby优化：使用索引，使group by字段有序，就不会用到临时表\n如果可以通过加索引来完成group by逻辑就再好不过了。但是，如果碰上不适合创建索引的场景，我们还是要老老实实做排序的。那么，这时候的group by要怎么优化呢？\ngroup by的几种实现算法，从中可以总结一些使用的指导原则：\n 如果对group by语句的结果没有排序要求，要在语句后面加 order by null； 尽量让group by过程用上表的索引，确认方法是explain结果里没有Using temporary 和 Using filesort； 如果group by需要统计的数据量不大，尽量只使用内存临时表；也可以通过适当调大tmp_table_size参数，来避免用到磁盘临时表； 如果数据量实在太大，使用SQL_BIG_RESULT这个提示，来告诉优化器直接使用排序算法得到group by的结果。   mysql自增id不连续 #  可见，唯一键冲突是导致自增主键id不连续的第一种原因。\n同样地，事务回滚也会产生类似的现象，这就是第二种原因。\n第三种原因：\n对于批量插入数据的语句，MySQL有一个批量申请自增id的策略：\n 语句执行过程中，第一次申请自增id，会分配1个； 1个用完以后，这个语句第二次申请自增id，会分配2个； 2个用完以后，还是这个语句，第三次申请自增id，会分配4个； 依此类推，同一个语句去申请自增id，每次申请到的自增id个数都是上一次的两倍。  insert…select，实际上往表t2中插入了4行数据。但是，这四行数据是分三次申请的自增id，第一次申请到了id=1，第二次被分配了id=2和id=3， 第三次被分配到id=4到id=7。\n由于这条语句实际只用上了4个id，所以id=5到id=7就被浪费掉了。之后，再执行insert into t2 values(null, 5,5)，实际上插入的数据就是（8,5,5)。\n这是主键id出现自增id不连续的第三种原因。\n 我们来对比一下这三种方法的优缺点。\n 物理拷贝的方式速度最快，尤其对于大表拷贝来说是最快的方法。如果出现误删表的情况，用备份恢复出误删之前的临时库，然后再把临时库中的表拷贝到生产库上，是恢复数据最快的方法。但是，这种方法的使用也有一定的局限性：  必须是全表拷贝，不能只拷贝部分数据； 需要到服务器上拷贝数据，在用户无法登录数据库主机的场景下无法使用； 由于是通过拷贝物理文件实现的，源表和目标表都是使用InnoDB引擎时才能使用。   用mysqldump生成包含INSERT语句文件的方法，可以在where参数增加过滤条件，来实现只导出部分数据。这个方式的不足之一是，不能使用join这种比较复杂的where条件写法。 用select … into outfile的方法是最灵活的，支持所有的SQL写法。但，这个方法的缺点之一就是，每次只能导出一张表的数据，而且表结构也需要另外的语句单独备份。  后两种方式都是逻辑备份方式，是可以跨引擎使用的。\n"},{"id":10,"href":"/docs/tech/go/atomic%E5%8C%85%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/","title":"Atomic包源码解析","section":"Go","content":"go语言中如何进行原子操作 #  在Go语言标准库中，sync/atomic包将底层硬件提供的原子操作封装成了Go的函数，主要分为5个系列的函数，分别是：\n func SwapXXXX(addr *int32, new int32) (old int32)系列：其实就是原子性的将new值保存到*addr并返回旧值。代码表示：  old = *addr *addr = new return old  func CompareAndSwapXXXX((addr *int64, old, new int64) (swapped bool)系列：其就是原子性的比较*addr和old的值，如果相同则将new赋值给*addr并返回真，代码表示：  if *addr == old{ *addr = new return ture } return false  func AddXXXX(addr *int64, delta int64) (new int64)系列：原子性的将val的值添加到*addr并返回新值。代码表示：  *addr += delta return *addr  func LoadXXXX(addr *uint32) (val uint32)系列：原子性的获取*addr的值 func StoreXXXX(addr *int32, val int32)原子性的将val值保存到*addr  Go语言在1.4版本时添加一个新的类型Value，此类型的值就相当于一个容器，可以被用来\u0026quot;原子地\u0026quot;存储(store)和加载(Load)任意类型的值。这些使用起来都还比较简单，就不写例子了，接下来我们一起看一看这些方法是如何实现的。\n源码解析 #  由于系列比较多。底层实现的方法也大同小异，这里就主要分析一下Value的实现方法吧。为什么不分析其他系列的呢？因为原子操作由底层硬件支持，所以看其他系列实现都要看汇编，Go的汇编是基于Plan9的，这个汇编语言真的资料甚少，我也是真的不懂，水平不够，也不自讨苦吃了，等后面真的能看懂这些汇编了，再来分析吧。这个网站有一些关于plan9汇编的知识，有兴趣可以看一看：http://doc.cat-v.org/plan_9/4th_edition/papers/asm。\nValue结构 #  我们先来看一下Value的结构：\ntype Value struct { v interface{} } Value结构里就只有一个字段，是interface类型，虽然这里是interface类型，但是这里要注意，第一次Store写入的类型就确定了之后写入的类型，否则会发生panic。因为这里是interface类型，所以为了之后写入与读取操作方便，又在这个包里定义了一个ifaceWords结构，其实他就是一个空interface，他的作用就是将interface分解成类型和数值。结构如下：\n// ifaceWords is interface{} internal representation. type ifaceWords struct { typ unsafe.Pointer data unsafe.Pointer } Value的写入操作 #  我们一起来看一看他是如何实现写入操作的：\n// Store sets the value of the Value to x. // All calls to Store for a given Value must use values of the same concrete type. // Store of an inconsistent type panics, as does Store(nil). func (v *Value) Store(x interface{}) { if x == nil { panic(\u0026#34;sync/atomic: store of nil value into Value\u0026#34;) } vp := (*ifaceWords)(unsafe.Pointer(v)) xp := (*ifaceWords)(unsafe.Pointer(\u0026amp;x)) for { typ := LoadPointer(\u0026amp;vp.typ) if typ == nil { // 第一次进入没有初始时，先初始化类型  // Attempt to start first store.  // Disable preemption so that other goroutines can use  // active spin wait to wait for completion; and so that  // GC does not see the fake type accidentally.  runtime_procPin() if !CompareAndSwapPointer(\u0026amp;vp.typ, nil, unsafe.Pointer(^uintptr(0))) { //使用初始值，用来等待第一次赋值类型结束  runtime_procUnpin() continue } // Complete first store.  StorePointer(\u0026amp;vp.data, xp.data) // 先赋值数据  StorePointer(\u0026amp;vp.typ, xp.typ) // 再赋值类型，就是为了下面方法防止第一次赋值未结束就又赋值  runtime_procUnpin() return } if uintptr(typ) == ^uintptr(0) { // 如果类型是中间值，说明初始化没结束，等待第一次结束  // First store in progress. Wait.  // Since we disable preemption around the first store,  // we can wait with active spinning.  continue } // First store completed. Check type and overwrite data.  if typ != xp.typ { panic(\u0026#34;sync/atomic: store of inconsistently typed value into Value\u0026#34;) } StorePointer(\u0026amp;vp.data, xp.data) return } } // Disable/enable preemption, implemented in runtime. func runtime_procPin() func runtime_procUnpin() 这段代码中的注释集已经告诉了我们，调用Store方法写入的类型必须与原类型相同，不一致便会发生panic。接下来分析代码实现：\n 首先判断条件写入参数不能为nil，否则触发panic 通过使用unsafe.Pointer将oldValue和newValue转换成ifaceWords类型。方便我们获取他的原始类型(typ)和值(data). 为了保证原子性，所以这里使用一个for换来处理，当已经有Store正在进行写入时，会进行等待. 如果还没写入过数据，那么获取不到原始类型，就会开始第一次写入操作，这里会把先调用runtime_procPin()方法禁止调度器对当前 goroutine 的抢占（preemption），这样也可以防止GC线程看到假类型。 调用CAS方法来判断当前地址是否有被抢占，这里大家可能对unsafe.Pointer(^uintptr(0))这一句话有点不明白，因为是第一个写入数据，之前是没有数据的，所以通过这样一个中间值来做判断，如果失败就会解除抢占锁，解除禁止调度器，继续循环等待. 设置中间值成功后，我们接下来就可以安全的把v设为传入的新值了，这里会先写入值，在写入类型(typ)，因为我们会根据ty来做完成判断。 第一次写入没完成，我们还会通过uintptr(typ) == ^uintptr(0)来进行判断，因为还是第一次放入的中间类型，他依然会继续等待第一次完成。 如果第一次写入完成，会检查上一次写入的类型与这次写入的类型是否一致，不一致则会抛出panic.  这里代码量没有多少，相信大家一定看懂了吧～。\nValue的读操作 #  先看一下代码：\n// Load returns the value set by the most recent Store. // It returns nil if there has been no call to Store for this Value. func (v *Value) Load() (x interface{}) { vp := (*ifaceWords)(unsafe.Pointer(v)) typ := LoadPointer(\u0026amp;vp.typ) if typ == nil || uintptr(typ) == ^uintptr(0) { // First store not yet completed.  return nil } data := LoadPointer(\u0026amp;vp.data) xp := (*ifaceWords)(unsafe.Pointer(\u0026amp;x)) xp.typ = typ xp.data = data return } 读取操作的代码就很简单了：1.第一步使用unsafe.Pointer将oldValue转换成ifaceWords类型，然后获取他的类型，如果没有类型或者类型出去中间值，那么说明现在还没数据或者第一次写入还没有完成。2. 通过检查后，调用LoadPointer方法可以获取他的值，然后构造一个新interface的typ和data返回。\n"},{"id":11,"href":"/docs/tech/go/golang%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D/","title":"Golang内存分配","section":"Go","content":"mspan #  mspan是一个包含起始地址、mspan规格、页的数量等内容的双端链表。\n小对象分配 #  当对一个小对象（\u0026lt;32KB）分配内存时，会将该对象所需的内存大小调整到某个能够容纳该对象的大小等级（size class）， 并查看 mcache 中对应等级的 mspan，通过扫描 mspan 的 freeindex 来确定是否能够进行分配。\n当没有可分配的 mspan 时，会从 mcentral 中获取一个所需大小空间的新的 mspan，从 mcentral 中分配会对其进行加锁， 但一次性获取整个 span 的过程均摊了对 mcentral 加锁的成本。\n如果 mcentral 的 mspan 也为空时，则它也会发生增长，从而从 mheap 中获取一连串的页，作为一个新的 mspan 进行提供。 而如果 mheap 仍然为空，或者没有足够大的对象来进行分配时，则会从操作系统中分配一组新的页（至少 1MB）， 从而均摊与操作系统沟通的成本。\n微对象分配 #  对于过小的微对象（\u0026lt;16B），它们的分配过程与小对象的分配过程基本类似，但是是直接存储在 mcache 上，并由其以 16B 的块大小直接进行管理和释放。\n大对象分配 #  大对象分配非常粗暴，不与 mcache 和 mcentral 沟通，直接绕过并通过 mheap 进行分配。\nGo的内存分配器在分配对象时，根据对象的大小，分成三类：小对象（小于等于16B）、一般对象（大于16B，小于等于32KB）、大对象（大于32KB）。\n大体上的分配流程：\n  32KB 的对象，直接从mheap上分配；\n  \u0026lt;=16B 的对象使用mcache的tiny分配器分配；\n  (16B,32KB] 的对象，首先计算对象的规格大小，然后使用mcache中相应规格大小的mspan分配；\n  如果mcache没有相应规格大小的mspan，则向mcentral申请\n  如果mcentral没有相应规格大小的mspan，则向mheap申请\n  如果mheap中也没有合适大小的mspan，则向操作系统申请\n  总结 #  Go语言的内存分配非常复杂，它的一个原则就是能复用的一定要复用。源码很难追，后面可能会再来一篇关于内存分配的源码阅读相关的文章。简单总结一下本文吧。\n文章从一个比较粗的角度来看Go的内存分配，并没有深入细节。一般而言，了解它的原理，到这个程度也可以了。\n Go在程序启动时，会向操作系统申请一大块内存，之后自行管理。 Go内存管理的基本单元是mspan，它由若干个页组成，每种mspan可以分配特定大小的object。 mcache, mcentral, mheap是Go内存管理的三大组件，层层递进。mcache管理线程在本地缓存的mspan；mcentral管理全局的mspan供所有线程使用；mheap管理Go的所有动态分配内存。 极小对象会分配在一个object中，以节省资源，使用tiny分配器分配内存；一般小对象通过mspan分配内存；大对象则直接由mheap分配内存。  "},{"id":12,"href":"/docs/tech/go/go%E5%B8%B8%E7%94%A8%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/","title":"Go常用设计模式","section":"Go","content":"创造型 #  单例 #  package singleton import ( \u0026#34;sync\u0026#34; ) type singleton struct { } var ins *singleton var once sync.Once func GetInsOr() *singleton { once.Do(func() { ins = \u0026amp;singleton{} }) return ins } 使用sync.Once来创建单例\n工厂模式 #  简单工厂 #  type Person struct { Name string Age int } func (p Person) Greet() { fmt.Printf(\u0026#34;Hi! My name is %s\u0026#34;, p.Name) } func NewPerson(name string, age int) *Person { return \u0026amp;Person{ Name: name, Age: age } } 抽象工厂 #  type Person interface { Greet() } type person struct { name string age int } func (p person) Greet() { fmt.Printf(\u0026#34;Hi! My name is %s\u0026#34;, p.name) } // Here, NewPerson returns an interface, and not the person struct itself func NewPerson(name string, age int) Person { return person{ name: name, age: age } } 它和简单工厂模式的唯一区别，就是它返回的是接口而不是结构体\n工厂方法模式 #  在简单工厂模式中，依赖于唯一的工厂对象，如果我们需要实例化一个产品，就要向工厂中传入一个参数，获取对应的对象；如果要增加一种产品，就要在工厂中修改创建产品的函数。这会导致耦合性过高，这时我们就可以使用工厂方法模式。\ntype Person struct { name string age int } func NewPersonFactory(age int) func(name string) Person { return func(name string) Person { return Person{ name: name, age: age, } } } // 创建具有默认年龄的工厂 func main(){ newBaby := NewPersonFactory(1) baby := newBaby(\u0026#34;john\u0026#34;) newTeenager := NewPersonFactory(16) teen := newTeenager(\u0026#34;jill\u0026#34;) } 结构型 #  策略模式 #  package strategy // 策略模式  // 定义一个策略类 type IStrategy interface { do(int, int) int } // 策略实现：加 type add struct{} func (*add) do(a, b int) int { return a + b } // 策略实现：减 type reduce struct{} func (*reduce) do(a, b int) int { return a - b } // 具体策略的执行者 type Operator struct { strategy IStrategy } // 设置策略 func (operator *Operator) setStrategy(strategy IStrategy) { operator.strategy = strategy } // 调用策略中的方法 func (operator *Operator) calculate(a, b int) int { return operator.strategy.do(a, b) } func TestStrategy(t *testing.T) { operator := Operator{} operator.setStrategy(\u0026amp;add{}) result := operator.calculate(1, 2) fmt.Println(\u0026#34;add:\u0026#34;, result) operator.setStrategy(\u0026amp;reduce{}) result = operator.calculate(2, 1) fmt.Println(\u0026#34;reduce:\u0026#34;, result) } 模板方法 #  package template import \u0026#34;fmt\u0026#34; type Cooker interface { fire() cooke() outfire() } // 类似于一个抽象类 type CookMenu struct { } func (CookMenu) fire() { fmt.Println(\u0026#34;开火\u0026#34;) } // 做菜，交给具体的子类实现 func (CookMenu) cooke() { } func (CookMenu) outfire() { fmt.Println(\u0026#34;关火\u0026#34;) } // 封装具体步骤 func doCook(cook Cooker) { cook.fire() cook.cooke() cook.outfire() } type XiHongShi struct { CookMenu } func (*XiHongShi) cooke() { fmt.Println(\u0026#34;做西红柿\u0026#34;) } type ChaoJiDan struct { CookMenu } func (ChaoJiDan) cooke() { fmt.Println(\u0026#34;做炒鸡蛋\u0026#34;) } 行为 #  代理 #  代理类与被代理类实现同一接口\n选项模式 #  一个可以创建带默认值的实例，一个可以定制化创建实例。\npackage options import ( \u0026#34;time\u0026#34; ) type Connection struct { addr string cache bool timeout time.Duration } const ( defaultTimeout = 10 defaultCaching = false ) type options struct { timeout time.Duration caching bool } // Option overrides behavior of Connect. type Option interface { apply(*options) } type optionFunc func(*options) func (f optionFunc) apply(o *options) { f(o) } func WithTimeout(t time.Duration) Option { return optionFunc(func(o *options) { o.timeout = t }) } func WithCaching(cache bool) Option { return optionFunc(func(o *options) { o.caching = cache }) } // Connect creates a connection. func Connect(addr string, opts ...Option) (*Connection, error) { options := options{ timeout: defaultTimeout, caching: defaultCaching, } for _, o := range opts { o.apply(\u0026amp;options) } return \u0026amp;Connection{ addr: addr, cache: options.caching, timeout: options.timeout, }, nil } "},{"id":13,"href":"/docs/tech/go/unsafe%E5%8C%85/","title":"Unsafe包","section":"Go","content":"什么是unsafe #  众所周知，Go语言被设计成一门强类型的静态语言，那么他的类型就不能改变了，静态也是意味着类型检查在运行前就做了。所以在Go语言中是不允许两个指针类型进行转换的，使用过C语言的朋友应该知道这在C语言中是可以实现的，Go中不允许这么使用是处于安全考虑，毕竟强制转型会引起各种各样的麻烦，有时这些麻烦很容易被察觉，有时他们却又隐藏极深，难以察觉。大多数读者可能不明白为什么类型转换是不安全的，这里用C语言举一个简单的例子：\nint main(){ double pi = 3.1415926; double *pv = \u0026amp;pi; void *temp = pd; int *p = temp; } 在标准C语言中，任何非void类型的指针都可以和void类型的指针相互指派，也可以通过void类型指针作为中介，实现不同类型的指针间接相互转换。上面示例中，指针pv指向的空间本是一个双精度数据，占8个字节，但是经过转换后，p指向的是一个4字节的int类型。这种发生内存截断的设计缺陷会在转换后进行内存访问是存在安全隐患。我想这就是Go语言被设计成强类型语言的原因之一吧。\n虽然类型转换是不安全的，但是在一些特殊场景下，使用了它，可以打破Go的类型和内存安全机制，可以绕过类型系统低效，提高运行效率。所以Go标准库中提供了一个unsafe包，之所以叫这个名字，就是不推荐大家使用，但是不是不能用，如果你掌握的特别好，还是可以实践的。\nunsafe 实现原理 #  在使用之前我们先来看一下unsafe的源码部分，标准库unsafe包中只提供了3``种方法，分别是:\nfunc Sizeof(x ArbitraryType) uintptr func Offsetof(x ArbitraryType) uintptr func Alignof(x ArbitraryType) uintptr  Sizeof(x ArbitrayType)方法主要作用是用返回类型x所占据的字节数，但并不包含x所指向的内容的大小，与C语言标准库中的Sizeof()方法功能一样，比如在32位机器上，一个指针返回大小就是4字节。 Offsetof(x ArbitraryType)方法主要作用是返回结构体成员在内存中的位置离结构体起始处(结构体的第一个字段的偏移量都是0)的字节数，即偏移量，我们在注释中看一看到其入参必须是一个结构体，其返回值是一个常量。 Alignof(x ArbitratyType)的主要作用是返回一个类型的对齐值，也可以叫做对齐系数或者对齐倍数。对齐值是一个和内存对齐有关的值，合理的内存对齐可以提高内存读写的性能。一般对齐值是2^n，最大不会超过8(受内存对齐影响).获取对齐值还可以使用反射包的函数，也就是说：unsafe.Alignof(x)等价于reflect.TypeOf(x).Align()。对于任意类型的变量x，unsafe.Alignof(x)至少为1。对于struct结构体类型的变量x，计算x每一个字段f的unsafe.Alignof(x，f)，unsafe.Alignof(x)等于其中的最大值。对于array数组类型的变量x，unsafe.Alignof(x)等于构成数组的元素类型的对齐倍数。没有任何字段的空struct{}和没有任何元素的array占据的内存空间大小为0，不同大小为0的变量可能指向同一块地址。  细心的朋友会发发现这三个方法返回的都是uintptr类型，这个目的就是可以和unsafe.poniter类型相互转换，因为*T是不能计算偏移量的，也不能进行计算，但是uintptr是可以的，所以可以使用uintptr类型进行计算，这样就可以可以访问特定的内存了，达到对不同的内存读写的目的。三个方法的入参都是ArbitraryType类型，代表着任意类型的意思，同时还提供了一个Pointer指针类型，即像void *一样的通用型指针。\ntype ArbitraryType int type Pointer *ArbitraryType // uintptr 是一个整数类型，它足够大，可以存储 type uintptr uintptr 上面说了这么多，可能会有点懵，在这里对三种指针类型做一个总结：\n *T：普通类型指针类型，用于传递对象地址，不能进行指针运算。 unsafe.poniter：通用指针类型，用于转换不同类型的指针，不能进行指针运算，不能读取内存存储的值(需转换到某一类型的普通指针) uintptr：用于指针运算，GC不把uintptr当指针，uintptr无法持有对象。uintptr类型的目标会被回收。  三者关系就是：unsafe.Pointer是桥梁，可以让任意类型的指针实现相互转换，也可以将任意类型的指针转换为uintptr进行指针运算，也就说uintptr是用来与unsafe.Pointer打配合，用于指针运算。画个图表示一下：\n 基本原理就说到这里啦，接下来我们一起来看看如何使用~\nunsafe.Pointer基本使用 #  我们在上一篇分析 atomic.Value源码时，看到atomic/value.go中定义了一个ifaceWords结构，其中typ和data字段类型就是unsafe.Poniter，这里使用unsafe.Poniter类型的原因是传入的值就是interface{}类型，使用unsafe.Pointer强转成ifaceWords类型，这样可以把类型和值都保存了下来，方便后面的写入类型检查。截取部分代码如下：\n// ifaceWords is interface{} internal representation. type ifaceWords struct { typ unsafe.Pointer data unsafe.Pointer } // Load returns the value set by the most recent Store. // It returns nil if there has been no call to Store for this Value. func (v *Value) Load() (x interface{}) { vp := (*ifaceWords)(unsafe.Pointer(v)) for { typ := LoadPointer(\u0026amp;vp.typ) // 读取已经存在值的类型  /** ..... 中间省略 **/ // First store completed. Check type and overwrite data.  if typ != xp.typ { //当前类型与要存入的类型做对比  panic(\u0026#34;sync/atomic: store of inconsistently typed value into Value\u0026#34;) } } 上面就是源码中使用unsafe.Pointer的一个例子，有一天当你准备读源码时，unsafe.pointer的使用到处可见。好啦，接下来我们写一个简单的例子，看看unsafe.Pointer是如何使用的。\nfunc main() { number := 5 pointer := \u0026amp;number fmt.Printf(\u0026#34;number:addr:%p, value:%d\\n\u0026#34;,pointer,*pointer) float32Number := (*float32)(unsafe.Pointer(pointer)) *float32Number = *float32Number + 3 fmt.Printf(\u0026#34;float64:addr:%p, value:%f\\n\u0026#34;,float32Number,*float32Number) } 运行结果：\nnumber:addr:0xc000018090, value:5 float64:addr:0xc000018090, value:3.000000 由运行可知使用unsafe.Pointer强制类型转换后指针指向的地址是没有改变，只是类型发生了改变。这个例子本身没什么意义，正常项目中也不会这样使用。\n总结一下基本使用：先把*T类型转换成unsafe.Pointer类型，然后在进行强制转换转成你需要的指针类型即可。\nSizeof、Alignof、Offsetof三个函数的基本使用 #  先看一个例子：\ntype User struct { Name string Age uint32 Gender bool // 男:true 女：false 就是举个例子别吐槽我这么用。。。。 } func func_example() { // sizeof  fmt.Println(unsafe.Sizeof(true)) fmt.Println(unsafe.Sizeof(int8(0))) fmt.Println(unsafe.Sizeof(int16(10))) fmt.Println(unsafe.Sizeof(int(10))) fmt.Println(unsafe.Sizeof(int32(190))) fmt.Println(unsafe.Sizeof(\u0026#34;asong\u0026#34;)) fmt.Println(unsafe.Sizeof([]int{1,3,4})) // Offsetof  user := User{Name: \u0026#34;Asong\u0026#34;, Age: 23,Gender: true} userNamePointer := unsafe.Pointer(\u0026amp;user) nNamePointer := (*string)(unsafe.Pointer(userNamePointer)) *nNamePointer = \u0026#34;Golang梦工厂\u0026#34; nAgePointer := (*uint32)(unsafe.Pointer(uintptr(userNamePointer) + unsafe.Offsetof(user.Age))) *nAgePointer = 25 nGender := (*bool)(unsafe.Pointer(uintptr(userNamePointer)+unsafe.Offsetof(user.Gender))) *nGender = false fmt.Printf(\u0026#34;u.Name: %s, u.Age: %d, u.Gender: %v\\n\u0026#34;, user.Name, user.Age,user.Gender) // Alignof  var b bool var i8 int8 var i16 int16 var i64 int64 var f32 float32 var s string var m map[string]string var p *int32 fmt.Println(unsafe.Alignof(b)) fmt.Println(unsafe.Alignof(i8)) fmt.Println(unsafe.Alignof(i16)) fmt.Println(unsafe.Alignof(i64)) fmt.Println(unsafe.Alignof(f32)) fmt.Println(unsafe.Alignof(s)) fmt.Println(unsafe.Alignof(m)) fmt.Println(unsafe.Alignof(p)) } 为了省事，把三个函数的使用示例放到了一起，首先看sizeof方法，我们可以知道各个类型所占字节大小，这里重点说一下int类型，Go语言中的int类型的具体大小是跟机器的 CPU位数相关的。如果 CPU 是32 位的，那么int就占4字节，如果 CPU是64位的，那么 int 就占8 字节，这里我的电脑是64位的，所以结果就是8字节。\n然后我们在看Offsetof函数，我想要修改结构体中成员变量，第一个成员变量是不需要进行偏移量计算的，直接取出指针后转换为unsafe.pointer，在强制给他转换成字符串类型的指针值即可。如果要修改其他成员变量，需要进行偏移量计算，才可以对其内存地址修改，所以Offsetof方法就可返回成员变量在结构体中的偏移量，也就是返回结构体初始位置到成员变量之间的字节数。看代码时大家应该要住uintptr的使用，不可以用一个临时变量存储uintptr类型，前面我们提到过用于指针运算，GC不把uintptr当指针，uintptr无法持有对象。uintptr类型的目标会被回收，所以你不知道他什么时候会被GC掉，那样接下来的内存操作会发生什么样的错误，咱也不知道。比如这样一个例子：\n// 切记不要这样使用 p1 := uintptr(userNamePointer) nAgePointer := (*uint32)(unsafe.Pointer(p1 + unsafe.Offsetof(user.Age))) 最后看一下Alignof函数，主要是获取变量的对齐值，除了int、uintptr这些依赖CPU位数的类型，基本类型的对齐值都是固定的，结构体中对齐值取他的成员对齐值的最大值，结构体的对齐涉及到内存对齐，我们在下面详细介绍。\n经典应用：string与[]byte的相互转换 #  实现string与byte的转换，正常情况下，我们可能会写出这样的标准转换：\n// string to []byte str1 := \u0026#34;Golang梦工厂\u0026#34; by := []byte(s1) // []byte to string str2 := string(by) 使用这种方式进行转换都会涉及底层数值的拷贝，所以想要实现零拷贝，我们可以使用unsafe.Pointer来实现，通过强转换直接完成指针的指向，从而使string和[]byte指向同一个底层数据。在reflect包中有·string和slice对应的结构体，他们的分别是：\ntype StringHeader struct { Data uintptr Len int } type SliceHeader struct { Data uintptr Len int Cap int } StringHeader代表的是string运行时的表现形式(SliceHeader同理)，通过对比string和slice运行时的表达可以看出，他们只有一个Cap字段不同，所以他们的内存布局是对齐的，所以可以通过unsafe.Pointer进行转换，因为可以写出如下代码：\nfunc stringToByte(s string) []byte { header := (*reflect.StringHeader)(unsafe.Pointer(\u0026amp;s)) newHeader := reflect.SliceHeader{ Data: header.Data, Len: header.Len, Cap: header.Len, } return *(*[]byte)(unsafe.Pointer(\u0026amp;newHeader)) } func bytesToString(b []byte) string{ header := (*reflect.SliceHeader)(unsafe.Pointer(\u0026amp;b)) newHeader := reflect.StringHeader{ Data: header.Data, Len: header.Len, } return *(*string)(unsafe.Pointer(\u0026amp;newHeader)) } 上面的代码我们通过重新构造slice header和string header完成了类型转换，其实[]byte转换成string可以省略掉自己构造StringHeader的方式，直接使用强转就可以，因为string的底层也是[]byte，强转会自动构造，省略后的代码如下：\nfunc bytesToString(b []byte) string { return *(* string)(unsafe.Pointer(\u0026amp;b)) } 虽然这种方式更高效率，但是不推荐大家使用，前面也提高到了，这要是不安全的，使用当不当会出现极大的隐患，一些严重的情况recover也不能捕获。\n内存对齐 #  现在计算机中内存空间都是按照byte划分的，从理论上讲似乎对任何类型的变量的访问可以从任何地址开始，但是实际情况是在访问特定类型变量的时候经常在特定的内存地址访问，这就需要各种类型数据按照一定的规则在空间上排列，而不是顺序的一个接一个的排放，这就对齐。\n对齐的作用和原因：CPU访问内存时，并不是逐个字节访问，而是以字长（word size)单位访问。比如32位的CPU，字长为4字节，那么CPU访问内存的单位也是4字节。这样设计可以减少CPU访问内存的次数，加大CPU访问内存的吞吐量。假设我们需要读取8个字节的数据，一次读取4个字节那么就只需读取2次就可以。内存对齐对实现变量的原子性操作也是有好处的，每次内存访问都是原子的，如果变量的大小不超过字长，那么内存对齐后，对该变量的访问就是原子的，这个特性在并发场景下至关重要。\n我们来看这样一个例子：\n// 64位平台，对齐参数是8 type User1 struct { A int32 // 4  B []int32 // 24  C string // 16  D bool // 1 } type User2 struct { B []int32 A int32 D bool C string } type User3 struct { D bool B []int32 A int32 C string } func main() { var u1 User1 var u2 User2 var u3 User3 fmt.Println(\u0026#34;u1 size is \u0026#34;,unsafe.Sizeof(u1)) fmt.Println(\u0026#34;u2 size is \u0026#34;,unsafe.Sizeof(u2)) fmt.Println(\u0026#34;u3 size is \u0026#34;,unsafe.Sizeof(u3)) } // 运行结果 MAC: 64位 u1 size is 56 u2 size is 48 u3 size is 56 从结果可以看出，字段放置不同的顺序，占用内存也不一样，这就是因为内存对齐影响了struct的大小，所以有时候合理的字段可以减少内存的开销。下面我们就一起来分析一下内存对齐，首先要明白什么是内存对齐的规则，C语言的对齐规则与Go语言一样，所以C语言的对齐规则对Go同样适用：\n 对于结构的各个成员，第一个成员位于偏移为0的位置，结构体第一个成员的偏移量（offset）**为0，以后每个成员相对于结构体首地址的 offset 都是**该成员大小与有效对齐值中较小那个的整数倍，如有需要编译器会在成员之间加上填充字节。 除了结构成员需要对齐，结构本身也需要对齐，结构的长度必须是编译器默认的对齐长度和成员中最长类型中最小的数据大小的倍数对齐。  好啦，知道规则了，我们现在来分析一下上面的例子，根据我的mac使用的64位CPU,对齐参数是8来分析，int32、[]int32、string、bool对齐值分别是4、8、8、1，占用内存大小分别是4、24、16、1，我们先根据第一条对齐规则分析User1：\n 第一个字段类型是int32，对齐值是4，大小为4，所以放在内存布局中的第一位. 第二个字段类型是[]int32，对齐值是8，大小为24，所以他的内存偏移值必须是8的倍数，所以在当前user1中，就不能从第4位开始了，必须从第5位开始，也就偏移量为8。第4,5,6,7位由编译器进行填充，一般为0值，也称之为空洞。第9位到第32位为第二个字段B. 第三个字段类型是string，对齐值是8，大小为16，所以他的内存偏移值必须是8的倍数，因为user1前两个字段就已经排到了第32位，所以下一位的偏移量正好是32，正好是字段C的对齐值的倍数，不用填充，可以直接排列第三个字段，也就是从第32位到48位第三个字段C. 第三个字段类型是bool，对齐值是1，大小为1，所以他的内存偏移值必须是1的倍数，因为user1前两个字段就已经排到了第48位，所以下一位的偏移量正好是48。正好是字段D的对齐值的倍数，不用填充，可以直接排列到第四个字段，也就是从48到第49位是第三个字段D. 好了现在第一条内存对齐规则后，内存长度已经为49字节，我们开始使用内存的第2条规则进行对齐。根据第二条规则，默认对齐值是8，字段中最大类型程度是24，取最小的那一个，所以求出结构体的对齐值是8，我们目前的内存长度是49，不是8的倍数，所以需要补齐，所以最终的结果就是56，补了7位。  说了这么多，画个图看一下吧：\n 现在你们应该懂了吧，按照这个思路再去分析其他两个struct吧，这里就不再分析了。\n对于内存对齐这里还有一最后需要注意的知识点，空struct不占用任何存储空间，空 struct{} 大小为 0，作为其他 struct 的字段时，一般不需要内存对齐。但是有一种情况除外：即当 struct{} 作为结构体最后一个字段时，需要内存对齐。因为如果有指针指向该字段, 返回的地址将在结构体之外，如果此指针一直存活不释放对应的内存，就会有内存泄露的问题（该内存不因结构体释放而释放）。来看一个例子：\nfunc main() { fmt.Println(unsafe.Sizeof(test1{})) // 8  fmt.Println(unsafe.Sizeof(test2{})) // 4 } type test1 struct { a int32 b struct{} } type test2 struct { a struct{} b int32 } 简单来说，对于任何占用0大小空间的类型，像struct {}或者[0]byte这些，如果该类型出现在结构体末尾，那么我们就假设它占用1个字节的大小。因此对于test1结构体，他看起来就是这样：`\ntype test1 struct { a int32 // b struct{}  b [1]byte } 因此在内存对齐时，最后结构体占用的字节就是8了。\n重点要注意的问题：不要在结构体定义的最后添加零大小的类型\n总结 #  好啦，终于又到文章的末尾了，我们来简单的总结一下，unsafe 包绕过了 Go 的类型系统，达到直接操作内存的目的，使用它有一定的风险性。但是在某些场景下，使用 unsafe 包提供的函数会提升代码的效率，Go 源码中也是大量使用 unsafe 包。\nunsafe 包定义了 Pointer 和三个函数：\ntype ArbitraryType int type Pointer *ArbitraryType func Sizeof(x ArbitraryType) uintptr func Offsetof(x ArbitraryType) uintptr func Alignof(x ArbitraryType) uintptr uintptr 可以和 unsafe.Pointer 进行相互转换，uintptr 可以进行数学运算。这样，通过 uintptr 和 unsafe.Pointer 的结合就解决了 Go 指针不能进行数学运算的限制。通过 unsafe 相关函数，可以获取结构体私有成员的地址，进而对其做进一步的读写操作，突破 Go 的类型安全限制。\n最后我们又学习了内存对齐的知识，这样设计可以减少CPU访问内存的次数，加大CPU访问内存的吞吐量，所以结构体中字段合理的排序可以更节省内存，注意：不要在结构体定义的最后添加零大小的类型。\n由Go 看源码必会知识之 unsafe 包 (qq.com) 转载 #  "},{"id":14,"href":"/docs/tech/java/java-test/","title":"Java Test","section":"Java","content":"mock接口或者抽象类 #  引入jar包 #  import 类 #  import static org.assertj.core.api.Assertions.assertThat; import static org.mockito.Matchers.any; import static org.mockito.Matchers.eq; import static org.mockito.Mockito.mock; import static org.mockito.Mockito.when; private PaasRepository repository = mock(PaasRepository.class); mock静态方法 #  PowerMockito.mockStatic(EnvUtil.class); when(EnvUtil.getTenantId()).thenReturn(\u0026#34;oki\u0026#34;); mock静态变量 #  import org.powermock.reflect.Whitebox;\rWhitebox.setInternalState(NiaPatchService.class, \u0026quot;instance\u0026quot;, (NiaPatchService) null);\r"},{"id":15,"href":"/docs/tech/mq/kafka/","title":"Kafka","section":"Mq","content":"partition ���д��� ˳��д���̣��������ô������� �������ִ�����ϵͳ��ҳ�洢 Page Cache �������ڴ����� I/O Ч�� �������㿽������ Producer ���������ݳ־û��� broker������ mmap �ļ�ӳ�䣬ʵ��˳���Ŀ���д�� Customer �� broker ��ȡ���ݣ����� sendfile���������ļ����� OS �ں˻���������ת�� NIO buffer �������緢�ͣ����� CPU ����\n��Ϣ��������\n ��Ҫʹ�� producer.send(msg)����Ҫʹ�� producer.send(msg, callback)����ס��һ��Ҫʹ�ô��лص�֪ͨ�� send ������ ���� acks = all��acks �� Producer ��һ�����������������ԡ����ύ����Ϣ�Ķ��塣�������ó� all�����������и��� Broker ��Ҫ���յ���Ϣ������Ϣ�����ǡ����ύ�����������ߵȼ��ġ����ύ�����塣 ���� retries Ϊһ���ϴ���ֵ�������� retries ͬ���� Producer �Ĳ�������Ӧǰ���ᵽ�� Producer �Զ����ԡ�������������˲ʱ����ʱ����Ϣ���Ϳ��ܻ�ʧ�ܣ���ʱ������ retries \u0026gt; 0 �� Producer �ܹ��Զ�������Ϣ���ͣ�������Ϣ��ʧ�� ���� unclean.leader.election.enable = false������ Broker �˵Ĳ����������Ƶ�����Щ Broker ���ʸ���ѡ������ Leader������һ�� Broker ����ԭ�ȵ� Leader ̫�࣬��ô��һ����Ϊ�µ� Leader����Ȼ��������Ϣ�Ķ�ʧ����һ�㶼Ҫ���ò������ó� false�������������������ķ����� ���� replication.factor \u0026gt;= 3����Ҳ�� Broker �˵Ĳ�������ʵ�������������ǣ����ý���Ϣ�ౣ�漸�ݣ��Ͼ�Ŀǰ��ֹ��Ϣ��ʧ����Ҫ���ƾ������ࡣ ���� min.insync.replicas \u0026gt; 1������Ȼ�� Broker �˲��������Ƶ�����Ϣ����Ҫ��д�뵽���ٸ����������ǡ����ύ�������óɴ��� 1 ����������Ϣ�־��ԡ���ʵ�ʻ�����ǧ����Ҫʹ��Ĭ��ֵ 1�� ȷ�� replication.factor \u0026gt; min.insync.replicas�������������ȣ���ôֻҪ��һ�������һ��������������޷����������ˡ����ǲ���Ҫ������Ϣ�ĳ־��ԣ���ֹ���ݶ�ʧ����Ҫ�ڲ����Ϳ����ԵĻ��������ɡ��Ƽ����ó� replication.factor = min.insync.replicas + 1�� ȷ����Ϣ�����������ύ��Consumer ���и����� enable.auto.commit�����ð������ó� false���������ֶ��ύλ�Ƶķ�ʽ������ǰ��˵�ģ������ڵ� Consumer ���̴߳����ĳ���������������Ҫ�ġ�  �ݵȺ�����\n�ݵ��� Producer �������� Producer ���� Kafka ������ͼΪ Kafka ʵ�־�ȷһ�δ����������ṩ�Ĺ��ߣ�ֻ�����ǵ����÷�Χ�ǲ�ͬ�ġ��ݵ��� Producer ֻ�ܱ�֤�����������Ự�ϵ���Ϣ�ݵ��ԣ��������ܹ���֤�����������Ự�����ݵ��ԡ��ӽ�����������������Ȼ�������� Producer �����ĸ��ࡣ\n�������м�����û�����ѵ����͡������ݵ��� Producer�������� Producer ������Ҫ�����ʵ��ʹ�ù����У�������Ҫ��ϸ�������������Ŀ������в������Ե�����������\nRebalance\nRebalance ��������һ��Э�飬�涨��һ�� Consumer Group �µ����� Consumer ���δ���һ�£������䶩�� Topic ��ÿ������������ĳ�� Group ���� 20 �� Consumer ʵ������������һ������ 100 �������� Topic�����������£�Kafka ƽ����Ϊÿ�� Consumer ���� 5 �����������������Ĺ��̾ͽ� Rebalance��\n��ô Consumer Group ��ʱ���� Rebalance �أ�Rebalance �Ĵ��������� 3 ����\n ����Ա�������������������µ� Consumer ʵ�������������뿪�飬�ֻ����� Consumer ʵ�����������߳����顣 ��������������������Consumer Group ����ʹ����������ʽ�ķ�ʽ�������⣬���� consumer.subscribe(Pattern.compile(��t.*c��)) �ͱ����� Group ������������ĸ t ��ͷ����ĸ c ��β�����⡣�� Consumer Group �����й����У����´�����һ�������������������⣬��ô�� Group �ͻᷢ�� Rebalance�� ���������ķ���������������Kafka ��ǰֻ����������һ�������ķ�������������������ʱ���ͻᴥ�����ĸ����������� Group ���� Rebalance��  __consumer_offsets\n�� Consumer ��λ��������Ϊһ������ͨ�� Kafka ��Ϣ���ύ�� __consumer_offsets �С�������ô˵��__consumer_offsets ����Ҫ�����Ǳ��� Kafka �����ߵ�λ����Ϣ\n����rebalance\nRebalance ������ʱ����������\n ����Ա���������仯 �����������������仯 ���������ķ����������仯  ��������ͨ��������ά�������������������������� Rebalance �����ǲ��ɱ����ġ���������������Ҫ˵˵��Ϊ����Ա�����仯�������� Rebalance �����α��⡣\n��һ���Ǳ�Ҫ Rebalance ����Ϊδ�ܼ�ʱ�������������� Consumer �����߳���Group �������������ˣ�����Ҫ��ϸ������session.timeout.ms �� heartbeat.interval.ms��ֵ��������������һЩ�Ƽ���ֵ�������ԡ����ԡ���Ӧ�����������������С�\n ���� session.timeout.ms = 6s�� ���� heartbeat.interval.ms = 2s�� Ҫ��֤ Consumer ʵ���ڱ��ж�Ϊ��dead��֮ǰ���ܹ��������� 3 �ֵ��������󣬼� session.timeout.ms \u0026gt;= 3 * heartbeat.interval.ms��  �ڶ����Ǳ�Ҫ Rebalance �� Consumer ����ʱ���������µ�\nmax.poll.interval.ms����ֵ�������Ե���Ϊ�ؼ�������Ҫ������Ԥ�ڵ� Rebalance�������ý��ò���ֵ���õô�һ�㣬������������������ʱ���Գ�һ�㡣���� MongoDB ����������˵������д MongoDB ���ʱ���� 7 ���ӣ���ô�����Խ��ò�������Ϊ 8 �������ҡ�\n�ܶ���֮������һ��Ҫ������Ϊ���ֲ������߼������������µ�����Ա�����������˳������Σ���֮���ص���Ҫ�����У�\n session.timeout.ms heartbeat.interval.ms max.poll.interval.ms GC ����  CommitFailedException\n ���̵�����Ϣ������ʱ�������磬֮ǰ����ϵͳ����һ����Ϣ��ʱ���� 100 ���룬�Ż�֮���ɹ����½��� 50 ���룬��ô��ʱ Consumer �˵� TPS ��������һ���� ���� Consumer ����������ϵͳ����һ����Ϣ������ʱ������ȡ���� Consumer �˲��� max.poll.interval.ms ��ֵ�������°��� Kafka �У��ò�����Ĭ��ֵ�� 5 ���ӡ��������������߼����ܼ򻯣���ô���߸ò���ֵ��һ�������İ취��ֵ��һ�����ǣ�Kafka 0.10.1.0 ֮ǰ�İ汾��û�����������ģ�������������Ȼ��ʹ�� 0.10.1.0 ֮ǰ�Ŀͻ��� API����ô����Ҫ���� session.timeout.ms ������ֵ�����ҵ��ǣ�session.timeout.ms �������������ĺ��壬�������Ӹò�����ֵ���ܻ������������ġ�����Ӱ�족����Ҳ�������� 0.10.1.0 �汾���� max.poll.interval.ms ���������ⲿ�ֺ����� session.timeout.ms �а���������ԭ��֮һ�� ��������ϵͳһ�������ѵ���Ϣ��������ȡ���� Consumer �˲��� max.poll.records ��ֵ����ǰ�ò�����Ĭ��ֵ�� 500 ������������һ�� KafkaConsumer.poll ���������෵�� 500 ����Ϣ������˵���ò����涨�˵��� poll �����ܹ����ص���Ϣ���������ޡ�����ǰ���ַ������㶼�����õĻ������ʹ˲���ֵ�Ǳ��� CommitFailedException �쳣���򵥵��ֶΡ� ����ϵͳʹ�ö��߳���������������Ӧ�����ǡ����߼���ͬʱҲ������ʵ�ֵĽ����취�ˡ�������˼·���ǣ�������ϵͳ�ֶ��������������̴߳��� poll �������ص�һ����Ϣ��֮ǰ��ʹ�� Kafka Consumer �������ݸ����ǵ��̵߳ģ����Ե������ٶ��޷�ƥ�� Kafka Consumer ��Ϣ���ص��ٶ�ʱ�����ͻ��׳� CommitFailedException �쳣�������Ƕ��̣߳����Ϳ��������ؿ����߳���������ʱ�������ѳ���������������Ŀǰ���˵�Ӳ���������÷�����ν�Ƿ�ֹ CommitFailedException ���ߵ��Ľ���֮������ʵ�ϣ��ܶ������Ĵ���������������ʹ�õĶ����������������� Apache Flink �ڼ��� Kafka ʱ�����Ǵ����˶��� KafkaConsumerThread �̣߳����д������̼߳����������ѡ������������������бף���������ʵ�������������ף��ر����ڶ����̼߳����δ���λ���ύ���������ϣ����Ǽ����׳�������ר�������������У��ҽ����غ�������һ�¶��߳����ѵ�ʵ�ַ�����  ������˵���� 3 �ַ�����\n ʹ�� Kafka �Դ��������й��� kafka-consumer-groups �ű��� ʹ�� Kafka Java Consumer API ���̡� ʹ�� Kafka �Դ��� JMX ����ָ�ꡣ  ����\n��һ���� Kafka �У������ֳ����ࣺ�쵼�߸�����Leader Replica����׷���߸�����Follower Replica����ÿ�������ڴ���ʱ��Ҫѡ��һ����������Ϊ�쵼�߸����������ĸ����Զ���Ϊ׷���߸�����\n�ڶ���Kafka �ĸ������Ʊ������ֲ�ʽϵͳҪ���ϸ�һЩ���� Kafka �У�׷���߸����ǲ������ṩ��������������˵���κ�һ��׷���߸�����������Ӧ�����ߺ������ߵĶ�д���������е����󶼱������쵼�߸���������������˵�����еĶ�д���󶼱��뷢���쵼�߸������ڵ� Broker���ɸ� Broker ����������׷���߸����������ͻ�����������Ψһ���������Ǵ��쵼�߸����첽��ȡ��Ϣ����д�뵽�Լ����ύ��־�У��Ӷ�ʵ�����쵼�߸�����ͬ����\n���������쵼�߸����ҵ��ˣ�����˵�쵼�߸������ڵ� Broker 崻�ʱ��Kafka ������ ZooKeeper �ṩ�ļ��ع����ܹ�ʵʱ��֪����������������һ�ֵ��쵼��ѡ�٣���׷���߸�����ѡһ����Ϊ�µ��쵼�ߡ��� Leader ����������������ֻ����Ϊ׷���߸������뵽��Ⱥ�С�\n2�����ô�\n1.����ʵ�֡�Read-your-writes����\n2.����ʵ�ֵ�������Monotonic Reads����\nISR #  Leader ������Ȼ���� ISR �С�Ҳ����˵��ISR ��ֻ��׷���߸������ϣ�����Ȼ���� Leader ������������ĳЩ�����£�ISR ֻ�� Leader ��һ��������\n������׼���� Broker �˲��� replica.lag.time.max.ms ����ֵ�����������ĺ����� Follower �����ܹ����� Leader �������ʱ����������ǰĬ��ֵ�� 10 �롣������˵��ֻҪһ�� Follower �������� Leader ������ʱ�䲻�������� 10 �룬��ô Kafka ����Ϊ�� Follower ������ Leader ��ͬ���ģ���ʹ��ʱ Follower �����б�������Ϣ�������� Leader �����е���Ϣ��\nUnclean �쵼��ѡ�٣�Unclean Leader Election��\n��Ȼ ISR �ǿ��Զ�̬�����ģ���ô��Ȼ�Ϳ��Գ������������Σ�ISR Ϊ�ա���Ϊ Leader ������Ȼ���� ISR �У����� ISR Ϊ���ˣ���˵�� Leader ����Ҳ���ҵ����ˣ�Kafka ��Ҫ����ѡ��һ���µ� Leader������ ISR �ǿգ���ʱ����ôѡ���� Leader �أ�\nKafka �����в��� ISR �еĴ��������Ϊ��ͬ��������ͨ����˵����ͬ���������� Leader ̫�࣬���ˣ�����ѡ����Щ������Ϊ�� Leader���Ϳ��ܳ������ݵĶ�ʧ���Ͼ�����Щ�����б�������ϢԶԶ�������� Leader �е���Ϣ���� Kafka �У�ѡ�����ָ����Ĺ��̳�Ϊ Unclean �쵼��ѡ�١�Broker �˲��� unclean.leader.election.enable �����Ƿ����� Unclean �쵼��ѡ����\n�����鿪��Unclean�����������ݶ�ʧ\n������ #  ������������Controller������ Apache Kafka �ĺ���������������Ҫ�������� Apache ZooKeeper �İ����¹�����Э������ Kafka ��Ⱥ��\n��һ���ɹ����� /controller �ڵ��� Broker �ᱻָ��Ϊ��������\n���������� #  1.����������������ɾ�������ӷ�����\n��������������������ָ�����������������ɶ� Kafka �����Ĵ�����ɾ���Լ��������ӵĲ��������仰˵��������ִ��kafka-topics �ű�ʱ���󲿷ֵĺ�̨�������ǿ����������ɵġ����� kafka-topics �ű����һ���ר�������������У���ϸ��������ʹ�÷�����\n2.�����ط���\n�����ط�����Ҫ��ָ��kafka-reassign-partitions �ű������������ű���������Ҳ�����ܣ��ṩ�Ķ�����������������ϸ���ȵķ��书�ܡ��ⲿ�ֹ���Ҳ�ǿ�����ʵ�ֵġ�\n3.Preferred �쵼��ѡ��\nPreferred �쵼��ѡ����Ҫ�� Kafka Ϊ�˱��ⲿ�� Broker ���ع��ض��ṩ��һ�ֻ� Leader �ķ�������ר������˵�����ߵ�ʱ������������̸ Preferred �쵼��ѡ�٣�������ֻ��Ҫ�˽���Ҳ�ǿ�������ְ����Χ�Ϳ����ˡ�\n4.��Ⱥ��Ա���������� Broker��Broker �����رա�Broker 崻���\n���ǿ������ṩ�ĵ� 4 �๦�ܣ������Զ��������� Broker��Broker �����رռ�����崻��������Զ�������������ǰ���ᵽ�� Watch ���ܺ� ZooKeeper ��ʱ�ڵ�����ʵ�ֵġ�\n���磬����������������Watch �������� ZooKeeper �� /brokers/ids �ڵ��µ��ӽڵ�����������Ŀǰ�������� Broker �������������� /brokers �´���ר���� znode �ڵ㡣һ���������ϣ�ZooKeeper ��ͨ�� Watch ���ƽ���Ϣ֪ͨ���͸��������������������������Զ��ظ�֪�������仯�������������������� Broker ��ҵ��\n���� Broker ���������������ڸո��ᵽ����һ�����ƣ���ʱ�ڵ���ÿ�� Broker �����󣬻��� /brokers/ids �´���һ����ʱ znode���� Broker 崻��������رպ󣬸� Broker �� ZooKeeper �ĻỰ���������� znode �ᱻ�Զ�ɾ����ͬ����ZooKeeper �� Watch ���ƽ���һ�������͸�����������������������֪���� Broker �رջ�崻��ˣ��Ӷ����С��ƺ󡱡�\n5.���ݷ���\n������������һ���๤�������������� Broker �ṩ���ݷ��񡣿������ϱ�������ȫ�ļ�ȺԪ������Ϣ���������� Broker �ᶨ�ڽ��տ�����������Ԫ���ݸ������󣬴Ӷ��������ڴ��еĻ������ݡ�\n��ˮλ������ #  �� Kafka �У���ˮλ��������Ҫ�� 2 ����\n ������Ϣ�ɼ��ԣ���������ʶ�����µ���Щ��Ϣ�ǿ��Ա����������ѵġ� ���� Kafka ���ɸ���ͬ����  λ��ֵ���ڸ�ˮλ����ϢҲ����δ�ύ��Ϣ��Ҳ����˵����ˮλ�ϵ���Ϣ�ǲ��ܱ����������ѵ���\nͼ�л���һ����־ĩ��λ�Ƶĸ���� Log End Offset����д�� LEO\nͬһ����������������ˮλֵ�������� LEO ֵ��\nLeader ������ Follower ��������ά�ȣ����ܽ�һ�¸�ˮλ�� LEO �ĸ��»��ơ�\n**Leader ����**\n�����������������߼����£�\n д����Ϣ�����ش��̡� ���·�����ˮλֵ�� i. ��ȡ Leader �������� Broker �˱���������Զ�̸��� LEO ֵ{LEO-1��LEO-2��������LEO-n}�� ii. ��ȡ Leader ������ˮλֵ��currentHW�� iii. ���� currentHW = min(currentHW, LEO-1��LEO-2��������LEO-n)��  ���� Follower ������ȡ��Ϣ���߼����£�\n ��ȡ���̣���ҳ���棩�е���Ϣ���ݡ� ʹ�� Follower �������������е�λ��ֵ����Զ�̸��� LEO ֵ�� ���·�����ˮλֵ�����岽���봦�������������Ĳ�����ͬ����  **Follower ����**\n�� Leader ��ȡ��Ϣ�Ĵ����߼����£�\n д����Ϣ�����ش��̡� ���� LEO ֵ�� ���¸�ˮλֵ�� i. ��ȡ Leader ���͵ĸ�ˮλֵ��currentHW�� ii. ��ȡ���� 2 �и��¹��� LEO ֵ��currentLEO�� iii. ���¸�ˮλΪ min(currentHW, currentLEO)��  leader epoch\n"},{"id":16,"href":"/docs/tech/nosql/elasticsearch/","title":"Elasticsearch","section":"Nosql","content":"缓Elasticsearch #  "},{"id":17,"href":"/docs/tech/nosql/redis/","title":"Redis","section":"Nosql","content":"键值对 #  redis用哈希表来保存所有键值对\nrehash也就是增加现有的哈希桶数量，让逐渐增多的entry元素能 在更多的桶之间分散保存，减少单个桶中的元素数量，从⽽减少单个桶中的冲突。\n 给哈希表2分配更⼤的空间，例如是当前哈希表1⼤⼩的两倍； 把哈希表1中的数据重新映射并拷⻉到哈希表2中； 释放哈希表1的空间。  采用渐进式rehash\n在第⼆步拷⻉数据时，Redis仍然正常处理客⼾端请求，每处理⼀个请求时，从哈希表1中的第 ⼀个索引位置开始，顺带着将这个索引位置上的所有entries拷⻉到哈希表2中；等处理下⼀个请求时，再顺 带拷⻉哈希表1中的下⼀个索引位置的entries。\n集合类型的底层数据结构主要有5种：整数数组、双向链表、哈希表、压缩列表和 跳表。\nredis都在内存中操作，有哈希表，跳表数据结构，单线程用多路复⽤的⾼性能I/O模型，select/epoll\nRedis只运⾏单线程的情况下，该机制允许内核中，同时存在多个监听套接字（listen）和已连接套接字(accept)\n AOF #  AOF⾥记录的是Redis收到的 每⼀条命令，这些命令是以⽂本形式保存的。\nAOF还有⼀个好处：它是在命令执⾏后才记录⽇志，所以不会阻塞当前的写操作\nAOF写回 #   Always，同步写回：每个写命令执⾏完，⽴⻢同步地将⽇志写回磁盘；(影响性能) Everysec，每秒写回：每个写命令执⾏完，只是先把⽇志写到AOF⽂件的内存缓冲区，每隔⼀秒把缓冲 区中的内容写⼊磁盘； No，操作系统控制的写回：每个写命令执⾏完，只是先把⽇志写到AOF⽂件的内存缓冲区，由操作系统 决定何时将缓冲区内容写回磁盘。  AOF重写 #  AOF⽂件是以追加的⽅式，逐⼀记录接收到的写命令的。当⼀个键值对被多条写命令反复修改 时，AOF⽂件会记录相应的多条命令。但是，在重写的时候，是根据这个键值对当前的最新状态，为它⽣成 对应的写⼊命令。这样⼀来，⼀个键值对在重写⽇志中只⽤⼀条命令就⾏了\n重写过程是由后台线程bgrewriteaof来完成的，这也是为了避免阻塞主线 程，导致数据库性能下降。\n⼀个拷⻉，两处⽇志\nfork会把主线程 的内存拷⻉⼀份给bgrewriteaof⼦进程\n第⼀处⽇志就是指正在使⽤的AOF⽇ 志，Redis会把这个操作写到它的缓冲区。第⼆处⽇志，就是指新的AOF重写⽇志\n RDB #  Redis提供了两个命令来⽣成RDB⽂件，分别是save和bgsave。\n save：在主线程中执⾏，会导致阻塞； bgsave：创建⼀个⼦进程，专⻔⽤于写⼊RDB⽂件，避免了主线程的阻塞，这也是Redis RDB⽂件⽣成的 默认配置。  Redis 4.0中提出了⼀个混合使⽤AOF⽇志和内存快照的⽅法。简单来说，内存快照以⼀定的频率执⾏，在两 次快照之间，使⽤AOF⽇志记录这期间的所有命令操作，T1和T2时刻的修改，⽤AOF⽇志记录，等到第⼆次做全量快照时，就可以清空AOF⽇志，因为 此时的修改都已经记录到快照中了，恢复时就不再⽤⽇志了。\n 数据不能丢失时，内存快照和AOF的混合使⽤是⼀个很好的选择； 如果允许分钟级别的数据丢失，可以只使⽤RDB； 如果只⽤AOF，优先使⽤everysec的配置选项，因为它在可靠性和性能之间取了⼀个平衡   Linux中CopyOnWrite实现原理 fork()之后，kernel把父进程中所有的内存页的权限都设为read-only，然后子进程的地址空间指向父进程。当父子进程都只读内存时，相安无事。当其中某个进程写内存时，CPU硬件检测到内存页是read-only的，于是触发页异常中断（page-fault），陷入kernel的一个中断例程。中断例程中，kernel就会把触发的异常的页复制一份，于是父子进程各自持有独立的一份。\nCopyOnWrite的好处： 1、减少分配和复制资源时带来的瞬时延迟； 2、减少不必要的资源分配； CopyOnWrite的缺点： 1、如果父子进程都需要进行大量的写操作，会产生大量的分页错误（页异常中断page-fault）;\nRedis中的CopyOnWrite Redis在持久化时，如果是采用BGSAVE命令或者BGREWRITEAOF的方式，那Redis会fork出一个子进程来读取数据，从而写到磁盘中。 总体来看，Redis还是读操作比较多。如果子进程存在期间，发生了大量的写操作，那可能就会出现很多的分页错误(页异常中断page-fault)，这样就得耗费不少性能在复制上。 而在rehash阶段上，写操作是无法避免的。所以Redis在fork出子进程之后，将负载因子阈值提高，尽量减少写操作，避免不必要的内存写入操作，最大限度地节约内存\n  主从 #  主从库之间采⽤的是读写分离的⽅式。\n 读操作：主库、从库都可以接收； 写操作：⾸先到主库执⾏，然后，主库将写操作同步给从库。  主从库间第⼀次同步 #   第⼀阶段是主从库间建⽴连接、协商同步的过程，主要是为全量复制做准备。在这⼀步，从库和主库建⽴起 连接，并告诉主库即将进⾏同步，主库确认回复后，主从库间就可以开始同步了 第二阶段是主库将所有数据同步给从库。从库收到数据后，在本地完成数据加载。这个过程依赖于内存快 照⽣成的RDB⽂件。 第三阶段：主库会把第⼆阶段执⾏过程中新收到的写命令，再发送给从库。当主库完成RDB⽂件发送后，就会把此时replication buffer中的修改操作发给从库，从库再重新执⾏这些操 作  长连接传播 #  完成全量复制，它们之间就会⼀直维护⼀个⽹络连接，主库会通过这个 连接将后续陆续收到的命令操作再同步给从库，这个过程也称为基于⻓连接的命令传播，可以避免频繁建⽴ 连接的开销。\n主从库间⽹络断了怎么办？ #  主从库会采⽤增量复制的⽅式继续同步。这⾥的奥妙就在于repl_backlog_buffer这个缓 冲区。\n当主从库断连后，主库会把断连期间收到的写操作命令，写⼊replication buffer，同时也会把这些操作命令 replicaof 所选从库的IP 6379也写⼊repl_backlog_buffer这个缓冲区。 repl_backlog_buffer是⼀个环形缓冲区，主库会记录⾃⼰写到的位置，从库则会记录⾃⼰已经读到的位 置。\n从库连上后，会发送psycn命令，并把slave_repl_offset到master，主库master_repl_offset和slave_repl_offset之间的差距\n因为repl_backlog_buffer是⼀个环形缓冲区，所以在缓冲区写满后，主库会继续写⼊，此时，就会覆盖掉之前写⼊的操作。如果从库的读取速度⽐较慢，就有可能导致从库还未读 取的操作被主库新写的操作覆盖了，这会导致主从库间的数据不⼀致。我们可以调整repl_backlog_size这个参数，即repl_backlog_size = 缓冲空间⼤⼩ * 2\n Redis的主从库同步的基本原理，总结来说，有三种模式：全量复制、基于⻓连接 的命令传播，以及增量复制。\n全量复制虽然耗时，但是对于从库来说，如果是第⼀次同步，全量复制是⽆法避免的，所以，我给你⼀个⼩ 建议：⼀个Redis实例的数据库不要太⼤，⼀个实例⼤⼩在⼏GB级别⽐较合适，这样可以减少RDB⽂件⽣ 成、传输和重新加载的开销。另外，为了避免多个从库同时和主库进⾏全量复制，给主库过⼤的同步压⼒， 我们也可以采⽤“主-从-从”这⼀级联模式，来缓解主库的压⼒。\n⻓连接复制是主从库正常运⾏后的常规同步阶段。在这个阶段中，主从库之间通过命令传播实现同步。不 过，这期间如果遇到了⽹络断连，增量复制就派上⽤场了。我特别建议你留意⼀下repl_backlog_size这个 配置参数。如果它配置得过⼩，在增量复制阶段，可能会导致从库的复制进度赶不上主库，进⽽导致从库重 新进⾏全量复制。所以，通过调⼤这个参数，可以减少从库在⽹络断连时全量复制的⻛险。\n replication buffer和repl_backlog_buffer区别\n replication buffer是主从库在进⾏全量复制时，主库上⽤于和从库连接的客⼾端的buffer，⽽ repl_backlog_buffer是为了⽀持从库增量复制，主库上⽤于持续保存写操作的⼀块专⽤buffer。\nRedis主从库在进⾏复制时，当主库要把全量复制期间的写操作命令发给从库时，主库会先创建⼀个客⼾ 端，⽤来连接从库，然后通过这个客⼾端，把写操作命令发给从库。在内存中，主库上的客⼾端就会对应⼀ 个buffer，这个buffer就被称为replication buffer。Redis通过client_buffer配置项来控制这个buffer的⼤ ⼩。主库会给每个从库建⽴⼀个客⼾端，所以replication buffer不是共享的，⽽是每个从库都有⼀个对应的 客⼾端。\nrepl_backlog_buffer是⼀块专⽤buffer，在Redis服务器启动后，开始⼀直接收写操作命令，这是所有从库 共享的。主库和从库会各⾃记录⾃⼰的复制进度，所以，不同的从库在进⾏恢复时，会把⾃⼰的复制进度 （slave_repl_offset）发给主库，主库就可以和它独⽴同步\n  哨兵 #  哨兵主要负责的 就是三个任务：监控、选主（选择主库）和通知。\n 监控：监控是指哨兵进程在运⾏时，周期性地给所有的主从库发送PING命令，检测它们是否仍然 在线运⾏。 选主：主库挂了以后，哨兵就需要从很多个从库⾥，按照⼀定的规 则选择⼀个从库实例，把它作为新的主库。 通知：在执⾏通知任务时，哨兵会把新主库的连接信息发给其他从库，让 它们执⾏replicaof命令，和新主库建⽴连接，并进⾏数据复制。同时，哨兵会把新主库的连接信息通知给客 ⼾端，让它们把请求操作发到新主库上。  主观下线和客观下线 #  哨兵进程会使⽤PING命令检测它⾃⼰和主、从库的⽹络连接情况，⽤来判断实例的状态。如果哨兵发现主 库或从库对PING命令的响应超时了，那么，哨兵就会先把它标记为“主观下线”。\n如果检测的是从库，那么，哨兵简单地把它标记为“主观下线”就⾏了。主库需要哨兵集群，再n/2+1的哨兵判断主观下线，标记客观下线，然后进入重新选主。\n哨兵集群选主 #  筛选：要检查从库的当前在线状态，还要判断它之前的⽹络连接状态。使⽤配置项down-after-milliseconds，在时间内超时10次，即筛选掉\n打分：\n​\t只要在某⼀轮中，有从库得分最⾼，那么它就是主库了\n​\t1、从库优 先级：过slave-priority配置项，给不同的从库设置不同优先级。优先级高的分高做主库\n​\t2、从库复制进度：主库会⽤master_repl_offset记 录当前的最新写操作在repl_backlog_buffer中的位置，⽽从库会⽤slave_repl_offset这个值记录当前的复 制进度。如果在所有从库中，有 从库的slave_repl_offset最接近master_repl_offset，那么它的得分就最⾼做主库\n​\t3、从库ID号：每个实例都会有⼀个ID，在优先级和复制进度都相同的情况下，ID号最⼩的从库得分最⾼，会被选为新主库。\n基于pub/sub机制的哨兵集群组成 #  主库：哨兵只要和主库建⽴起了连接，就可以在主库上发布消息了，⽐如说发布它⾃⼰的连接信息（IP和端⼝）。 同时，它也可以从主库上订阅消息，获得其他哨兵发布的连接信息。当多个哨兵实例都在主库上做了发布和 订阅操作后，它们之间就能知道彼此的IP地址和端⼝。\n在主从集群中，主库上有⼀个名为“sentinel:hello”的频道，不同哨兵就是通过它来相互发现， 实现互相通信的。\n从库：由哨兵向主库发送INFO命令来完成的。就像下图所⽰，哨兵2给主库发送INFO命令，主库接受到这个 命令后，就会把从库列表返回给哨兵。接着，哨兵就可以根据从库列表中的连接信息，和每个从库建⽴连 接，并在这个连接上持续地对从库进⾏监控。\n基于pub/sub机制的客⼾端事件通知 #  客⼾端从哨兵这⾥订阅消息了。具体的操作步骤是，客⼾端读取哨兵的配 置⽂件后，可以获得哨兵的地址和端⼝，和哨兵建⽴⽹络连接。然后，我们可以在客⼾端执⾏订阅命令，来 获取不同的事件消息。\n由哪个哨兵执⾏主从切换？ #  “Leader选举”。因为最终执⾏主从切换的哨兵称为Leader，投票过程就是确定 Leader。\n第⼀，拿到半数以上的赞成票；\n第⼆， 拿到的票数同时还需要⼤于等于哨兵配置⽂件中的quorum值。\n以3个哨兵为例，假设此时的quorum设置为 2，那么，任何⼀个想成为Leader的哨兵只要拿到2张赞成票，就可以了。\n如果哨兵集群只有2个实例，此时，⼀个哨兵要想成为Leader，必须获得2票，⽽不是1票。\n Redis Cluster #  在Redis Cluster⽅案中，⼀个切⽚集群共有16384个哈希槽，这些哈希槽类似于数据分 区，每个键值对都会根据它的key，被映射到⼀个哈希槽中。集群重定向MOVED ACK，MOVED会更新客⼾端缓存的哈希槽分配信息，ACK不会\nString的坑 #  保存了1亿张图⽚的信息，⽤了约6.4GB的内存，⼀个图⽚ID和图⽚存储对象ID的记 录平均⽤了64字节。\nSDS #  buf：字节数组，保存实际数据。为了表⽰字节数组的结束，Redis会⾃动在数组最后加⼀个“\\0”，这 就会额外占⽤1个字节的开销。 len：占4个字节，表⽰buf的已⽤⻓度。 alloc：也占个4字节，表⽰buf的实际分配⻓度，⼀般⼤于len。\nString类型来说，除了SDS的额外开销，还有⼀个来⾃于RedisObject结构体的开销。\nRedisObject #    当保存的是Long类型整数时，RedisObject中的指针就直接赋值为整数数据了，这样就不⽤额外的 指针再指向整数了，节省了指针的空间开销。\n  当保存的是字符串数据，并且字符串⼩于等于44字节时，RedisObject中的元数据、指针和SDS 是⼀块连续的内存区域，这样就可以避免内存碎⽚。这种布局⽅式也被称为embstr编码⽅式。\n  当字符串⼤于44字节时，SDS的数据量就开始变多了，Redis就不再把SDS和RedisObject布局在⼀起 了，⽽是会给SDS分配独⽴的空间，并⽤指针指向SDS结构。这种布局⽅式被称为raw编码模式。\n  Redis会使⽤⼀个全局哈希表保存所有键值对，哈希表的每⼀项是dictEntry结构中有三个8字节的指针，分别指向key、value以及下⼀个 dictEntry，三个指针共24字节，到Redis使⽤的内存分配库jemalloc，所以会是32\nString保存64的原因就是 16 + 16 + 32 =64，redis元数据占了48字节\n优化方案使用压缩列表 #  prev_len，表⽰前⼀个entry的⻓度。prev_len有两种取值情况：1字节或5字节。取值1字节时，表⽰上 ⼀个entry的⻓度⼩于254字节。虽然1字节的值能表⽰的数值范围是0到255，但是压缩列表中zlend的取 值默认是255，因此，就默认⽤255表⽰整个压缩列表的结束，其他表⽰⻓度的地⽅就不能再⽤255这个值 了。所以，当上⼀个entry⻓度⼩于254字节时，prev_len取值为1字节，否则，就取值为5字节。\nlen：表⽰⾃⾝⻓度，4字节；\nencoding：表⽰编码⽅式，1字节；\ncontent：保存实际数据。\n根据上场景，只需 1+4+1+8=16 保存一个数据\n 统计 #  聚合统计 #  用set\nSUNIONSTORE user280680 user280680 user280680:20200803 // 并集\rSDIFFSTORE user:new user280680:20200804 user280680 // 差集\rSINTERSTORE user280680:rem user280680:20200803 user280680:20200804 //交集\r如果数据量特别大，你可以从主从集群中选择⼀个从库，让它专⻔负责聚合计算，或 者是把数据读取到客⼾端，在客⼾端来完成聚合统计\n排序统计 #  List是按照元素进⼊List的顺序进⾏排序的，⽽Sorted Set可以根据元素的权重来排序，\n在⾯对需要展⽰最新列表、排⾏榜等场景时，如果数据更新频繁或者需要分⻚显⽰，建议你优先考虑 使⽤Sorted Set。\n⼆值状态统计 #  只有0/1，二值，使用bitmap\n基数统计 #  一般会想到用Set或hash，但是数据量大就不行，考虑使用HyperLogLog\nHyperLogLog是⼀种⽤于统计基数的数据集合类型，它的最⼤优势就在于，当集合元素数量⾮常多时，它 计算基数所需的空间总是固定的，⽽且还很⼩。\nHyperLogLog的统计规则是基于概率完成的，所以它给出的统计结果是有 ⼀定误差的，标准误算率是0.81%。这也就意味着，你使⽤HyperLogLog统计的UV是100万，但实际的UV 可能是101万。虽然误差率不算⼤，但是，如果你需要精确统计结果的话，最好还是继续⽤Set或Hash类 型。\nGEO #  可以用来操作经纬度\n Redis的基本对象结构 #  type：表⽰值的类型，涵盖了我们前⾯学习的五⼤基本类型；\nencoding：是值的编码⽅式，⽤来表⽰Redis中实现各个基本类型的底层数据结构，例如SDS、压缩列 表、哈希表、跳表等；\nlru：记录了这个对象最后⼀次被访问的时间，⽤于淘汰过期的键值对；\nrefcount：记录了对象的引⽤计数；\n*ptr：是指向数据的指针。\n Redis中保存时间序列数据 #  点查询，根据⼀个时间戳，查询相应时间的数据；\n范围查询，查询起始和截⽌时间戳范围内的数据；\n聚合计算，针对起始和截⽌时间戳范围内的所有数据进⾏计算，例如求最⼤/最⼩值，求均值等\n基于Hash和Sorted Set保存时间序列数据 #  hash查某个时间没有问题，但是查范围不支持，同时再存Sorted Set解决。\n保证hash和sorted set原子，需要简单的事务的MULTI和EXEC命令\n聚合统计 ⼤量数据在Redis实例和客⼾端间频繁传输，这会和其他操作命令竞争⽹络资源，导致其他操作变慢。\n优缺点：⼀个是，在执⾏聚合计算时，我们需要把数据读取到客⼾端再进⾏聚合， 当有⼤量数据要聚合时，数据传输开销⼤；另⼀个是，所有的数据会在两个数据类型中各保存⼀份，内存开 销不⼩。不过，我们可以通过设置适当的数据过期时间，释放内存，减⼩内存压⼒。\n基于RedisTimeSeries模块保存时间序列数据 #  RedisTimeSeries是Redis的⼀个扩展模块。它专⻔⾯向时间序列数据提供了数据类型和访问接⼝，并且⽀ 持在Redis实例上直接对数据进⾏按时间范围的聚合计算。\n如果你的部署环境中⽹络带宽⾼、Redis实例内存⼤，可以优先考虑第⼀种⽅案；\n如果你的部署环境中⽹络、内存资源有限，⽽且数据量⼤，聚合计算频繁，需要按数据集合属性查询，可 以优先考虑第⼆种⽅案。\n Redis消息队列 #  消息队列在存取消息时，必须要满⾜三个需求，分别是消息保序、处理重复的消息和保证消息可靠 性。\n基于List的消息队列解决⽅案 #  ⽣产者可以使⽤LPUSH命令把要发送的消息依次写⼊List，⽽消费者则可以使⽤RPOP命令，从 List的另⼀端按照消息的写⼊顺序，依次读取消息并进⾏处理。\nBRPOP命令也称为阻塞式读取，客⼾端在没有读到队列数 据时，⾃动阻塞，直到有新的数据写⼊队列，再开始读取新数据。\nBRPOPLPUSH命令保证消息可靠，这个命令的作⽤是让消费者程序从⼀个List中读取消 息，同时，Redis会把这个消息再插⼊到另⼀个List（可以叫作备份List）留存。\nList类型并 不⽀持消费组的实现。\n基于Streams的消息队列解决⽅案 #   XADD：插⼊消息，保证有序，可以⾃动⽣成全局唯⼀ID； XREAD：⽤于读取消息，可以按ID读取数据； XREADGROUP：按消费组形式读取消息； XPENDING和XACK：XPENDING命令可以⽤来查询每个消费组内所有消费者已读取但尚未确认的消息， ⽽XACK命令⽤于向消息队列确认消息处理已完成。   如何避免单线程模型的阻塞？ #   Redis内部的阻塞式操作； CPU核和NUMA架构的影响； Redis关键系统配置； Redis内存碎⽚； Redis缓冲区。  阻塞点 #  客⼾端：⽹络IO，键值对增删改查操作，数据库操作；\n磁盘：⽣成RDB快照，记录AOF⽇志，AOF⽇志重写；\n主从节点：主库⽣成、传输RDB⽂件，从库接收RDB⽂件、清空数据库、加载RDB⽂件；\n切⽚集群实例：向其他实例传输哈希槽信息，数据迁移。\n 集合全量查询和聚合操作； bigkey删除； 清空数据库； AOF⽇志同步写； 从库加载RDB⽂件。  和客⼾端交互时的阻塞点 #  第⼀ 个阻塞点：集合全量查询和聚合操作。集合元素全量查询操作 HGETALL、SMEMBERS，以及集合的聚合统计操作，例如求交、并和差集。\n第⼆个阻塞点：bigkey删除操作\n第三个阻塞点：清空数据库。\n和磁盘交互时的阻塞点 #  采⽤⼦进程的⽅式⽣成 RDB快照⽂件，以及执⾏AOF⽇志重写操作。这样⼀来，这两个操作由⼦进程负责执⾏，慢速的磁盘IO就不 会阻塞主线程了。\nRedis直接记录AOF⽇志时，会根据不同的写回策略对数据做落盘保存。\n第四个阻塞点了：AOF⽇志同步写。\n主从节点交互时的阻塞点 #  从库在清空当前数据库后，还需要把RDB⽂件加载到内存，这个过程的快慢和RDB⽂件的⼤⼩密切相 关，RDB⽂件越⼤，加载过程越慢，\n所以，加载RDB⽂件就成为了Redis的第五个阻塞点。\n切⽚集群实例交互时的阻塞点 #  迁移的是bigkey的话，就会造成主线程的阻塞，因为 Redis Cluster使⽤了同步迁移。\n哪些阻塞点可以异步执行 #  读操作是典型的关键路径操作，所以集合全量查询和聚合操作和从库加载RDB文件不能异步，剩余的可以。\n异步的⼦线程机制 #  Redis主线程启动后，会使⽤操作系统提供的pthread_create函数创建3个⼦线程，分别由它们负责AOF⽇志 写操作、键值对删除以及⽂件关闭的异步执⾏。\n阻塞点的解决方案 #   主线程通过⼀个链表形式的任务队列和⼦线程进⾏交互。当收到键值对删除和清空数据库的操作时，主线程 会把这个操作封装成⼀个任务，放⼊到任务队列中，然后给客⼾端返回⼀个完成信息，表明删除已经完成。等到后台⼦线程从任务队列中读取任务后，才开始实际删除键值对， 并释放相应的内存空间。因此，我们把这种异步删除也称为惰性删除（lazy free） 当AOF⽇志配置成everysec选项后，主线程会把AOF写⽇志操作封装成⼀个任务，也放到 任务队列中。 键值对删除：当你的集合类型中有⼤量元素（例如有百万级别或千万级别元素）需要删除时，我建议你使 ⽤UNLINK命令。 清空数据库：可以在FLUSHDB和FLUSHALL命令后加上ASYNC选项，这样就可以让后台⼦线程异步地清 空数据库 集合全量查询和聚合操作：可以使⽤SCAN命令，分批读取数据，再在客⼾端进⾏聚合计算； 从库加载RDB⽂件：把主库的数据量⼤⼩控制在2~4GB左右，以保证RDB⽂件能以较快的速度加载。   CPU对redis影响 #  在CPU多核的场景下，⽤taskset命令把Redis实例和⼀个核绑定，可 以减少Redis实例在不同核上被来回调度执⾏的开销，避免较⾼的尾延迟；在多CPU的NUMA架构下，如果 你对⽹络中断程序做了绑核操作，建议你同时把Redis实例和⽹络中断程序绑在同⼀个CPU Socket的不同核 上，这样可以避免Redis跨Socket访问内存中的⽹络数据的时间开销。\n绑核的⻛险和解决⽅案 #  ⽅案⼀：⼀个Redis实例对应绑⼀个物理核 #  给Redis实例绑核时，我们不要把⼀个实例和⼀个逻辑核绑定，⽽要和⼀个物理核绑定，也就是说，把⼀ 个物理核的2个逻辑核都⽤上。\n方案二：改源码 #   Redis响应 #  方法：\n 查看Redis的响应延迟 当前环境下的Redis基线性能 redis-cli命令提供了‒intrinsic-latency选  Redis⾃⾝操作特性的影响 #  慢查询： #   ⽤其他⾼效命令代替。⽐如说，如果你需要返回⼀个SET中的所有成员时，不要使⽤SMEMBERS命令， ⽽是要使⽤SSCAN多次迭代返回，避免⼀次返回⼤量数据，造成线程阻塞。 当你需要执⾏排序、交集、并集操作时，可以在客⼾端完成，⽽不要⽤SORT、SUNION、SINTER这些 命令，以免拖慢Redis实例 因为KEYS命令需要遍历存储的键值对，所以操作延时⾼。不建议生产环境使用  过期key： #  Redis每100毫秒会删除⼀些过期key，具体的算法如 下：\n 采样ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP个数的key，并将其中过期的key全部删除； 如果超过25%的key过期了，则重复删除的过程，直到过期key的⽐例降⾄25%以下。  第一种问题不大，第二种原因时频繁使⽤带有相同时间参数的EXPIREAT 命令设置过期key。删除操作时阻塞的（Redis 4.0后可以⽤异步线程机制来减少阻塞影响）\n判 断Redis变慢的⽅法，⼀个是看响应延迟，⼀个是看基线性能。\n两种排查和解决Redis变慢 这个问题的⽅法：\n 从慢查询命令开始排查，并且根据业务需求替换慢查询命令； 排查过期key的时间设置，并根据实际使⽤需求，设置不同的过期时间。  ⽂件系统：AOF模式 #  当主线程使⽤后台⼦线程执⾏了⼀次fsync，需要再次把新接收的操作记录写回磁盘时，如果主线程发现上 ⼀次的fsync还没有执⾏完，那么它就会阻塞。所以，如果后台⼦线程执⾏的fsync频繁阻塞的话（⽐如AOF 重写占⽤了⼤量的磁盘IO带宽），主线程也会阻塞，导致Redis性能变慢。\n解决方案：使用固态硬盘\n操作系统：swap #  触发swap的原因主要是物理机器内存不⾜\n Redis实例⾃⾝使⽤了⼤量的内存，导致物理机器的可⽤内存不⾜； 和Redis实例在同⼀台机器上运⾏的其他进程，在进⾏⼤量的⽂件读写操作。⽂件读写本⾝会占⽤系统内 存，这会导致分配给Redis实例的内存量变少，进⽽触发Redis发⽣swap。  解决方案：增加机器的内存或者使⽤Redis集群\n操作系统：内存⼤⻚ #  解决方案：关闭内存大页\nchecklist #   获取Redis实例在当前环境下的基线性能。 是否⽤了慢查询命令？如果是的话，就使⽤其他命令替代慢查询命令，或者把聚合计算命令放在客⼾端 做。 是否对过期key设置了相同的过期时间？对于批量删除的key，可以在每个key的过期时间上加⼀个随机 数，避免同时删除。 是否存在bigkey？ 对于bigkey的删除操作，如果你的Redis是4.0及以上的版本，可以直接利⽤异步线程 机制减少主线程阻塞；如果是Redis 4.0以前的版本，可以使⽤SCAN命令迭代删除；对于bigkey的集合查 询和聚合操作，可以使⽤SCAN命令在客⼾端完成。 Redis AOF配置级别是什么？业务层⾯是否的确需要这⼀可靠性级别？如果我们需要⾼性能，同时也允许 数据丢失，可以将配置项no-appendfsync-on-rewrite设置为yes，避免AOF重写和fsync竞争磁盘IO资 源，导致Redis延迟增加。当然， 如果既需要⾼性能⼜需要⾼可靠性，最好使⽤⾼速固态盘作为AOF⽇志 的写⼊盘。 Redis实例的内存使⽤是否过⼤？发⽣swap了吗？如果是的话，就增加机器内存，或者是使⽤Redis集 群，分摊单机Redis的键值对数量和内存压⼒。同时，要避免出现Redis和其他内存需求⼤的应⽤共享机 器的情况。 在Redis实例的运⾏环境中，是否启⽤了透明⼤⻚机制？如果是的话，直接关闭内存⼤⻚机制就⾏了。 是否运⾏了Redis主从集群？如果是的话，把主库实例的数据量⼤⼩控制在2~4GB，以免主从复制时，从 库因加载⼤的RDB⽂件⽽阻塞。 是否使⽤了多核CPU或NUMA架构的机器运⾏Redis实例？使⽤多核CPU时，可以给Redis实例绑定物理 核；使⽤NUMA架构时，注意把Redis实例和⽹络中断处理程序运⾏在同⼀个CPU Socket上。   内存碎片 #  如何判断是否有内存碎⽚ #  Redis⾃⾝提供了INFO命令，可以⽤来查询内存使⽤的详细信息\nINFO memory\r# Memory\rused_memory:1073741736\rused_memory_human:1024.00M\rused_memory_rss:1997159792\r....\rmem_fragmentation_ratio:1.86\rmem_fragmentation_ratio的指标，它表⽰的就是Redis当前的内存碎⽚率。used_memory_rss和used_memory相除的结果\n mem_fragmentation_ratio ⼤于1但⼩于1.5。这种情况是合理的。这是因为，刚才我介绍的那些因素 是难以避免的。毕竟，内因的内存分配器是⼀定要使⽤的，分配策略都是通⽤的，不会轻易修改；⽽外因 由Redis负载决定，也⽆法限制。所以，存在内存碎⽚也是正常的。 mem_fragmentation_ratio ⼤于 1.5 。这表明内存碎⽚率已经超过了50%。⼀般情况下，这个时候， 我们就需要采取⼀些措施来降低内存碎⽚率了。  如何清理内存碎⽚？ #   重启Redis实例 从4.0-RC3版本以后，Redis⾃⾝提供了⼀种内存碎⽚⾃动清理。碎⽚清理是有代价的，操作系统需要把多份数据拷⻉到新位置，把原有空间释放出 来，这会带来时间开销。  清理参数\n只要一项不满足就结束\n active-defrag-threshold-lower 10：表⽰内存碎⽚空间占操作系统分配给Redis的总空间⽐例达到10% 时，开始清理。 active-defrag-ignore-bytes 100mb：表⽰内存碎⽚的字节数达到100MB时，开始清理；  ⾃动内存碎⽚清理功能在执⾏时，还会监控清理操 作占⽤的CPU时间\n active-defrag-cycle-min 25： 表⽰⾃动清理过程所⽤CPU时间的⽐例不低于25%，保证清理能正常开 展； active-defrag-cycle-max 75：表⽰⾃动清理过程所⽤CPU时间的⽐例不⾼于75%，⼀旦超过，就停⽌ 清理，从⽽避免在清理时，⼤量的内存拷⻉阻塞Redis，导致响应延迟升⾼。  内存空间效率 #   info memory命令是⼀个好⼯具，可以帮助你查看碎⽚率的情况； 碎⽚率阈值是⼀个好经验，可以帮忙你有效地判断是否要进⾏碎⽚清理了； 内存碎⽚⾃动清理是⼀个好⽅法，可以避免因为碎⽚导致Redis的内存实际利⽤率降低，提升成本收益 率。   如何应对输⼊缓冲区溢出 #  ⼀是把缓冲区调⼤， ⼆是从数据命令的发送和处理速度⼊⼿。\nRedis的客⼾端输⼊缓冲区⼤⼩的上限阈值，在代码中就设定为了1GB，无法调大缓冲区。\n避免客⼾端写⼊bigkey，\n输出缓冲区溢出 #  避免bigkey操作返回⼤量数据结果；\n避免在线上环境中持续使⽤MONITOR命令。\n使⽤client-output-buffer-limit设置合理的缓冲区⼤⼩上限，或是缓冲区连续写⼊时间和写⼊量上限。\n全量复制缓冲区 #  如果在全量复制时，从节点接收和加载RDB较慢，同时主节点接收到了⼤量的写命令，写命令在复制 缓冲区中就会越积越多，最终导致溢出。\n使⽤client-output-buffer-limit配置项，来设置合理的复制缓冲区⼤⼩。\n增量复制缓冲区 #  repl_backlog_size⼤⼩\n总结 #    缓冲区溢出导致⽹络连接关闭：普通客⼾端、订阅客⼾端，以及从节点客⼾端，它们使⽤的缓冲区，本质 上都是Redis客⼾端和服务器端之间，或是主从节点之间为了传输命令数据⽽维护的。这些缓冲区⼀旦发 ⽣溢出，处理机制都是直接把客⼾端和服务器端的连接，或是主从节点间的连接关闭。⽹络连接关闭造成 的直接影响，就是业务程序⽆法读写Redis，或者是主从节点全量同步失败，需要重新执⾏。\n  缓冲区溢出导致命令数据丢失：主节点上的复制积压缓冲区属于环形缓冲区，⼀旦发⽣溢出，新写⼊的命 令数据就会覆盖旧的命令数据，导致旧命令数据的丢失，进⽽导致主从节点重新进⾏全量复制。\n  针对命令数据发送过快过⼤的问题，对于普通客⼾端来说可以避免bigkey，⽽对于复制缓冲区来说，就是 避免过⼤的RDB⽂件。\n  针对命令数据处理较慢的问题，解决⽅案就是减少Redis主线程上的阻塞操作，例如使⽤异步的删除操 作。\n  针对缓冲区空间过⼩的问题，解决⽅案就是使⽤client-output-buffer-limit配置项设置合理的输出缓冲 区、复制缓冲区和复制积压缓冲区⼤⼩。当然，我们不要忘了，输⼊缓冲区的⼤⼩默认是固定的，我们⽆ 法通过配置来修改它，除⾮直接去修改Redis源码。\n   缓存类型 #  只读缓冲 #  要修改数据A，此时，数据A在Redis中也缓存了，那么，应⽤会先直接在数 据库⾥修改A，并把Redis中的A删除。等到应⽤需要读取数据A时，会发⽣缓存缺失，此时，应⽤从数据库 中读取A，并写⼊Redis，以便后续请求从缓存中直接读取\n读写缓存 #  同步直写是指，写请求发给缓存的同时，也会发给后端数据库进⾏处理，等到缓存和数据库都写完数据，才 给客⼾端返回。(数据可靠)\n异步写回策略，则是优先考虑了响应延迟。此时，所有写请求都先在缓存中处理。等到这些增改的数据要 被从缓存中淘汰出来时，缓存将它们写回后端数据库。（断电时，未从缓存写回，数据不可靠）\n缓存建议容量 #  建议把缓存容量 设置为总数据量的15%到30%，兼顾访问性能和内存空间开销。\n缓存淘汰策略 #   在设置了过期时间的数据中进⾏淘汰，包括volatile-random、volatile-ttl、volatile-lru、volatile\u0002lfu（Redis 4.0后新增）四种。 在所有数据范围内进⾏淘汰，包括allkeys-lru、allkeys-random、allkeys-lfu（Redis 4.0后新增）三种。 不进⾏数据淘汰的策略，只有noeviction这⼀种。  过期时间淘汰 #   volatile-ttl在筛选时，会针对设置了过期时间的键值对，根据过期时间的先后进⾏删除，越早过期的越先 被删除。 volatile-random就像它的名称⼀样，在设置了过期时间的键值对中，进⾏随机删除。 volatile-lru会使⽤LRU算法筛选设置了过期时间的键值对。 volatile-lfu会使⽤LFU算法选择设置了过期时间的键值对。  所有数据淘汰 #   allkeys-random策略，从所有键值对中随机选择并删除数据； allkeys-lru策略，使⽤LRU算法在所有数据中进⾏筛选。 allkeys-lfu策略，使⽤LFU算法在所有数据中进⾏筛选。  LRU #  链表管理开销大，Redis默认会记录 每个数据的最近⼀次访问的时间戳（由键值对数据结构RedisObject中的lru字段记录）。然后，Redis在决 定淘汰的数据时，第⼀次会随机选出N个数据，把它们作为⼀个候选集合。接下来，Redis会⽐较这N个数据 的lru字段，把lru字段值最⼩的数据从缓存中淘汰出去。\n第二次能进 ⼊候选集合的数据的lru字段值必须⼩于候选集合中最⼩的lru值\nLRU使用建议 #   优先使⽤allkeys-lru策略。这样，可以充分利⽤LRU这⼀经典缓存算法的优势，把最近最常访问的数据留 在缓存中，提升应⽤的访问性能。如果你的业务数据中有明显的冷热数据区分，我建议你使⽤allkeys-lru 策略。 如果业务应⽤中的数据访问频率相差不⼤，没有明显的冷热数据区分，建议使⽤allkeys-random策略， 随机选择淘汰的数据就⾏。 如果你的业务中有置顶的需求，⽐如置顶新闻、置顶视频，那么，可以使⽤volatile-lru策略，同时不给这 些置顶数据设置过期时间。这样⼀来，这些需要置顶的数据⼀直不会被删除，⽽其他数据会在过期时根据 LRU规则进⾏筛选。   缓存一致性 #     操作顺序 是否有并发请求 潜在问题 现象 应对方案     先删缓存，再更新数据库 无 缓存删除成功，但数据库更新失败 应用从数据库读到旧数据 重试数据库更新   先删缓存，再更新数据库 有 缓存删除后，尚未更新数据库，有并发读请求 并发请求从数据库读到旧值，并且更新到缓存，导致后续请求都读取旧值 延迟双删   先更新数据库，再删除缓存 无 数据库更新成功，但缓存删除失败 应用从缓存读到旧数据 重试缓存删除   先更新数据库，再删除缓存 有 数据库更新成功后，尚未删除缓存，有并发读 并发请求从缓存中读到旧值 等待缓存删除完成，期间会有不一致数据短暂存在    优先使⽤先更新数 据库再删除缓存的⽅法，原因主要有两个：\n 先删除缓存值再更新数据库，有可能导致请求因缓存缺失⽽访问数据库，给数据库带来压⼒； 如果业务应⽤中读取数据库和写缓存的时间不好估算，那么，延迟双删中的等待时间就不好设置。  如果业务层要求必须读取⼀致的数据，那 么，我们就需要在更新数据库时，先在Redis缓存客⼾端暂存并发读请求，等数据库更新完、缓存值删除 后，再读取数据，从⽽保证数据⼀致性。\n 缓存雪崩、击穿、穿透 #     问题 原因 方案     缓存雪崩 大量数据同时过期缓存实例宕机 给缓存数据的过期时间加上小的随机数，避免同时过期服务降级服务熔断请求限流Redis缓存主从集群   缓存击穿 访问非常频繁的热点数据过期 不给热点数据设置过期时间，一直保留   缓存穿透 缓存和数据库中都没有要访问的数据 缓存空值或缺省值使用布隆过滤器快速判断请求入口前端对请求合法性检查    尽量使⽤预防式⽅案：\n 针对缓存雪崩，合理地设置数据过期时间，以及搭建⾼可靠缓存集群； 针对缓存击穿，在缓存访问⾮常频繁的热点数据时，不要设置过期时间； 针对缓存穿透，提前在⼊⼝前端实现恶意请求检测，或者规范数据库的数据删除操作，避免误删除   缓存污染 #  LFU #  LFU缓存策略是在LRU策略基础上，为每个数据增加了⼀个计数器，来统计这个数据的访问次数。当使⽤ LFU策略筛选淘汰数据时，⾸先会根据数据的访问次数进⾏筛选，把访问次数最低的数据淘汰出缓存。如果 两个数据的访问次数相同，LFU策略再⽐较这两个数据的访问时效性，把距离上⼀次访问时间更久的数据淘 汰出缓存。\nRedis在实现LFU策略的时候，只是把原来24bit⼤⼩的lru字段，⼜进⼀步拆分成了两部分。\n ldt值：lru字段的前16bit，表⽰数据的访问时间戳； counter值：lru字段的后8bit，表⽰数据的访问次数。  在实现LFU策略时，Redis并没有采⽤数据每被访问⼀次，就给 对应的counter值加1的计数规则，⽽是采⽤了⼀个更优化的计数规则。\n我们可以通过设置不同的lfu_log_factor配置项，来控制计数器值增加的速度，避 免counter值很快就到255了。\nLRU和LFU两个策略关注的数据访问特征各有侧重， LRU策略更加关注数据的时效性，⽽LFU策略更加关注数据的访问频次。\n Redis的两种原⼦操作⽅法 #   把多个操作在Redis中实现成⼀个操作，也就是单命令操作； (INCR/DECR) 把多个操作写到⼀个Lua脚本中，以原⼦性⽅式执⾏单个Lua脚本。   Redis分布式锁 #  加锁\n 加锁包括了读取锁变量、检查锁变量值和设置锁变量值三个操作，但需要以原⼦操作的⽅式完成，所 以，我们使⽤SET命令带上NX选项来实现加锁； 锁变量需要设置过期时间，以免客⼾端拿到锁后发⽣异常，导致锁⼀直⽆法释放，所以，我们在SET命令 执⾏时加上EX/PX选项，设置其过期时间； 锁变量的值需要能区分来⾃不同客⼾端的加锁操作，以免在释放锁时，出现误释放操作，所以，我们使 ⽤SET命令设置锁变量值时，每个客⼾端设置的值是⼀个唯⼀值，⽤于标识客⼾端。  释放锁\n释放锁也包含了读取锁变量值、判断锁变量值和删除锁变量三个操作，不过，我们⽆法使⽤单 个命令来实现，所以，我们可以采⽤Lua脚本执⾏释放锁操作，通过Redis原⼦性地执⾏Lua脚本，来保证释 放锁操作的原⼦性。\n单个Redis实例实现分布式锁时，会⾯临实例异常或崩溃的情况。Redis也提供了Redlock算法，⽤来实现基于多个实例的分布式锁\n Redis的事务机制能保证哪些属性？ #  原子性 #  保证原子性：在执⾏EXEC命令前，客⼾端发送的操作命令本⾝就有错误。（⽐如语法错误，使⽤了不存在 的命令），在命令⼊队时就被Redis实例判断出来了。\n不保证原子性：事务操作⼊队时，命令和操作的数据类型不匹配，但Redis实例没有检查出错误。\n总结：\n 命令⼊队时就报错，会放弃事务执⾏，保证原⼦性； 命令⼊队时没报错，实际执⾏时报错，不保证原⼦性； EXEC命令执⾏时实例故障，如果开启了AOF⽇志，可以保证原⼦性。  一致性 #  在命令执⾏错误或Redis发⽣故障的情况下，Redis事务机制对⼀致性属性是有保证的\n隔离性 #   并发操作在EXEC命令前执⾏，此时，隔离性的保证要使⽤WATCH机制来实现，否则隔离性⽆法保证； 并发操作在EXEC命令后执⾏，此时，隔离性可以保证。  持久性 #  不管Redis采⽤什么持久化模式RDB、AOF，事务的持久性属性是得不到保证的。\n小结 #  Redis通过MULTI、EXEC、DISCARD和WATCH四个命令来⽀ 持事务机制，这4个命令的作⽤\n 主从故障 #  主从数据不一致 #  原因：主从库间的命令复制是异步进⾏的。\n解决：\n 在硬件环境配置⽅⾯，我们要尽量保证主从库间的⽹络连接状况良好。例如，我们要避免把主从库部 署在不同的机房，或者是避免把⽹络通信密集的应⽤（例如数据分析应⽤）和Redis主从库部署在⼀起。 另外，我们还可以开发⼀个外部程序来监控主从库间的复制进度。开发⼀个监控程序，先⽤INFO replication命 令查到主、从库的进度，然后，我们⽤master_repl_offset减去slave_repl_offset，这样就能得到从库和主 库间的复制进度差值了。  读取过期数据 #  Redis同时使⽤了两种策略来删除过期的数据，分别是惰性删除策略和定期删除策略。\n是Redis 3.2之前的版本，那么，从库在服务读请求时，并 不会判断数据是否过期，⽽是会返回过期数据。在3.2版本后，Redis做了改进，如果读取的数据已经过期 了，从库虽然不会删除，但是会返回空值，这就避免了客⼾端读到过期数据。所以，在应⽤主从集群时，尽 量使⽤Redis 3.2及以上版本。\n小结 #   主从数据不⼀致。Redis采⽤的是异步复制，所以⽆法实现强⼀致性保证（主从数据时时刻刻保持⼀致），数据不⼀致是难以避免的。我给你提供了应对⽅法：保证良好⽹络环境，以及使⽤程序监控从库复 制进度，⼀旦从库复制进度超过阈值，不让客⼾端连接从库。 对于读到过期数据，这是可以提前规避的，⼀个⽅法是，使⽤Redis 3.2及以上版本；另外，你也可以使 ⽤EXPIREAT/PEXPIREAT命令设置过期时间，避免从库上的数据过期时间滞后。不过，这⾥有个地⽅需要 注意下，因为EXPIREAT/PEXPIREAT设置的是时间点，所以，主从节点上的时钟要保持⼀致，具体的做 法是，让主从节点和相同的NTP服务器（时间服务器）进⾏时钟同步。  不合理配置项导致的服务挂掉 #  protected-mode 配置项 #  这个配置项的作⽤是限定哨兵实例能否被其他服务器访问。当这个配置项设置为yes时，哨兵实例只能在部 署的服务器本地进⾏访问。当设置为no时，其他服务器也可以访问这个哨兵实例。\n我们在应⽤主从集群时，要注意将protected-mode 配置项设置为no，并且将bind配置项设置为其它 哨兵实例的IP地址。这样⼀来，只有在bind中设置了IP地址的哨兵，才可以访问当前实例，既保证了实例间 能够通信进⾏主从切换，也保证了哨兵的安全性。\ncluster-node-timeout配置项 #  这个配置项设置了Redis Cluster中实例响应⼼跳消息的超时时间。\nRedis Cluster集群中为每个实例配置了“⼀主⼀从”模式时，如果主实例发⽣故障，从实例会切换 为主实例，受⽹络延迟和切换操作执⾏的影响，切换时间可能较⻓，就会导致实例的⼼跳超时（超出 cluster-node-timeout）。\n将cluster-node-timeout调⼤些（例如10到20秒）。\n 脑裂 #   和主库部署在同⼀台服务器上的其他程序临时占⽤了⼤量资源（例如CPU资源），导致主库资源使⽤受 限，短时间内⽆法响应⼼跳。其它程序不再使⽤资源时，主库⼜恢复正常。 主库⾃⾝遇到了阻塞的情况，例如，处理bigkey或是发⽣内存swap（你可以复习下第19讲中总结的导致 实例阻塞的原因），短时间内⽆法响应⼼跳，等主库阻塞解除后，⼜恢复正常的请求处理了。  通过合理地配置参数min-slaves-to-write和min-slaves-max-lag，来预防脑裂的发⽣。\n假设从库有K个，可以将min-slaves-to-write设置为K/2+1（如果K等于1，就设为 1），将min-slaves-max-lag设置为⼗⼏秒（例如10〜20s），在这个配置下，如果有⼀半以上的从库和主 库进⾏的ACK消息延迟超过⼗⼏秒，我们就禁⽌主库接收客⼾端写请求。\n该方式还是可能会造成数据不一致，只能减少丢失的\n Redis秒杀 #    ⽀持⾼并发。这个很简单，Redis本⾝⾼速处理请求的特性就可以⽀持⾼并发。⽽且，如果有多个秒杀商 品，我们也可以使⽤切⽚集群，⽤不同的实例保存不同商品的库存，这样就避免，使⽤单个实例导致所 有的秒杀请求都集中在⼀个实例上的问题了。不过，需要注意的是，当使⽤切⽚集群时，我们要先⽤CRC 算法计算不同秒杀商品key对应的Slot，然后，我们在分配Slot和实例对应关系时，才能把不同秒杀商品 对应的Slot分配到不同实例上保存。\n  保证库存查验和库存扣减原⼦性执⾏。针对这条要求，我们就可以使⽤Redis的原⼦操作或是分布式锁这 两个功能特性来⽀撑了。库存查验和库存扣减这两个操作要保证⼀起执⾏，⼀个直接的⽅法就是使⽤Redis的原⼦操作，这里使用LUA脚本。分布式锁，即拿到锁，查验库存等\u0026hellip;\n  使⽤切⽚集群中的不同实例来分别保存分布式锁和商品库存信息。\n 前端静态⻚⾯的设计。秒杀⻚⾯上能静态化处理的⻚⾯元素，我们都要尽量静态化，这样可以充分利⽤ CDN或浏览器缓存服务秒杀开始前的请求。 请求拦截和流控。在秒杀系统的接⼊层，对恶意请求进⾏拦截，避免对系统的恶意攻击，例如使⽤⿊名单禁⽌恶意IP进⾏访问。如果Redis实例的访问压⼒过⼤，为了避免实例崩溃，我们也需要在接⼊层进⾏ 限流，控制进⼊秒杀系统的请求数量。 库存信息过期时间处理。Redis中保存的库存信息其实是数据库的缓存，为了避免缓存击穿问题，我们不 要给库存信息设置过期时间。 数据库订单异常处理。如果数据库没能成功处理订单，可以增加订单重试功能，保证订单最终能被成功 处理。   数据倾斜 #  数据量倾斜：在某些情况下，实例上的数据分布不均衡，某个实例上的数据特别多。\n 数据中有bigkey，导致某个实例的数据量增加； Slot⼿⼯分配不均，导致某个或某些实例上有⼤量数据； 使⽤了Hash Tag，导致数据集中到某些实例上。  数据访问倾斜：虽然每个集群实例上的数据量相差不⼤，但是某个实例上的数据是热点数据，被访问得⾮ 常频繁。⽽数据访问倾斜的主要原因就是有热点数据存在，导致⼤量访问请求集中到了热点数据所在的实例上。\n   倾斜类型 倾斜成因 应对方法     数据量倾斜 存在bigkey 业务层避免创建bigkey把集合类型的bigkey拆分成多个小集合，分散保存   数据量倾斜 Slot手工分配不均 指定运维规范，避免把过多Slot分配到一个实例上   数据量倾斜 使用Hash Tag，导致大量数据集中到一个Slot 如果Hash Tag会造成数据倾斜，有限避免数据倾斜，不适用Hash Tag   数据访问倾斜 存在热点数据 采用带有不同key前缀的多副本方法     RedisCluster通信 #  Redis Cluster实例间以Gossip协议进⾏通信的机制。Redis Cluster运⾏时，各实例间 需要通过PING、PONG消息进⾏信息交换，这些⼼跳消息包含了当前实例和部分其它实例的状态信息，以及 Slot分配信息。这种通信机制有助于Redis Cluster中的所有实例都拥有完整的集群状态信息。\n如果我们盲⽬地对Redis Cluster进⾏扩容，就可能 会遇到集群性能变慢的情况。虽然我们可以通过调整cluster-node-timeout配置项减少⼼跳消息的占⽤带宽 情况，但是，在实际应⽤中，如果不是特别需要⼤容量集群，我建议你把Redis Cluster 的规模控制在 400~500个实例。\n假设单个实例每秒能⽀撑8万请求操作（8万QPS），每个主实例配置1个从实例，那么，400~ 500个实例可 ⽀持 1600万~2000万QPS（200/250个主实例*8万QPS=1600/2000万QPS），这个吞吐量性能可以满⾜不少 业务应⽤的需求。\n"},{"id":18,"href":"/docs/","title":"Introduction","section":"老三炮的笔记","content":"程序员的自我修养 #  记录各种 #  Est in vagis et Pittheus tu arge accipiter regia iram vocatur nurus. Omnes ut olivae sensit arma sorori deducit, inesset crudus, ego vetuere aliis, modo arsit? Utinam rapta fiducia valuere litora adicit cursu, ad facies  Su学习各种 #  Ea furtique risere fratres edidit terrae magis. Colla tam mihi tenebat: miseram excita suadent es pecudes iam. Concilio quam velatus posset ait quod nunc! Fragosis suae dextra geruntur functus vulgata.   "}]